{
	"id": 66094736,
	"body": "\u003ca id=\"c18\"\u003e\u003c/a\u003eComment 18:\n\n\u003cpre\u003eThis is a great start.  Depending on which piece of the stack you're trying to stress, I\ncan imagine the output you'd want would look very different.  For example, to test the\nscanner you'd want all kinds of odd tokens: nested comments, string literals with odd\nescape sequences, various numeric literals, even just line noise.  To test the type\nchecker you'd want well-formed ASTs that are mostly well-typed, but with random types,\nassignments, identifiers, constants, etc.  To test code generation, you'd want only\nwell-typed programs that exercise control flow, operator semantics, etc.  They might all\nhave a lot in common, but more intelligence or structure is needed in the sentence\ngenerator for later passes.  Looking over the regression tests for each tool might give\nyou some hints for where to focus your efforts.\u003c/pre\u003e",
	"user": {
		"login": "adonovan",
		"id": 5658175,
		"type": "User",
		"site_admin": false
	},
	"created_at": "2014-05-21T01:55:19Z",
	"updated_at": "2014-12-08T10:44:16Z"
}
