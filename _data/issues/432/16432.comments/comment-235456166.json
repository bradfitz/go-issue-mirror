{
	"id": 235456166,
	"body": "\u003e Great. It sounds like my RPC benchmark was getting similar results to the real thing.\r\n\r\nYes. I ran your RPC benchmark (replacing the \"golang.org/x/benchmarks/gcbench.newer/heapgen\" import with \"github.com/aclements/go-gcbench/gcbench/heapgen\") and its behavior is similar to what I see in my application.\r\n\r\nIts behavior also reopens one of my initial questions in this issue: is it right for the GC to consume _all_ available resources at the expense of mutator latency?\r\n\r\nWhen run with go1.7rc3, the RPC benchmark shows a few Ps making very slow progress on a few Gs, as the run queue grows. After the GC, there's a flurry of mutator activity as the run queue drains.\r\n\r\n\u003cimg width=\"1512\" alt=\"screen shot 2016-07-26 at 5 47 41 pm\" src=\"https://cloud.githubusercontent.com/assets/230685/17160328/195f525a-5359-11e6-9b99-3ccb9de81bc4.png\"\u003e\r\n\r\n```\r\ngo run .../github.com/aclements/go-gcbench/gcbench/progs/rpc.go -trace /tmp/trace.bin.go17rc3 -benchtime 10s\r\nBenchmarkRPC/reqs-per-sec:10000/ballast:64MB/gomaxprocs:4\r\n1\r\n13.0 GCs/op\r\n1.27 GCs/sec\r\n33000 95%ile-ns/sweepTerm\r\n160000 95%ile-ns/markTerm\r\n525 MB-marked/CPU/sec\r\n-0.0263 95%ile-heap-overshoot\r\n-0.231 5%ile-heap-overshoot\r\n0.879 95%ile-CPU-util\r\n9721 reqs/sec\r\nWarning: -0.231 5%ile-heap-overshoot \u003c -0.200\r\nWarning: 0.879 95%ile-CPU-util \u003e 0.500\r\n2016/07/26 17:30:13 cleaning up client\r\n2016/07/26 17:30:13 closing 294 connections\r\nclient-measured request latency:\r\n[    13.803µs,    16.982µs) 1\r\n[    16.982µs,    20.892µs) 1\r\n[    20.892µs,    25.703µs) 1\r\n[    25.703µs,    31.622µs) 1\r\n[    31.622µs,    38.904µs) 8\r\n[    38.904µs,    47.863µs) 3134\r\n[    47.863µs,    58.884µs) 35491\r\n[    58.884µs,    72.443µs) 23327\r\n[    72.443µs,    89.125µs) 16944\r\n[    89.125µs,   109.647µs) 10246\r\n[   109.647µs,   134.896µs) 4406\r\n[   134.896µs,   165.958µs) 1275\r\n[   165.958µs,   204.173µs) 269\r\n[   204.173µs,   251.188µs) 64\r\n[   251.188µs,   309.029µs) 34\r\n[   309.029µs,   380.189µs) 38\r\n[   380.189µs,   467.735µs) 30\r\n[   467.735µs,   575.439µs) 35\r\n[   575.439µs,   707.945µs) 28\r\n[   707.945µs,   870.963µs) 32\r\n[   870.963µs,  1.071519ms) 29\r\n[  1.071519ms,  1.318256ms) 39\r\n[  1.318256ms,   1.62181ms) 42\r\n[   1.62181ms,  1.995262ms) 33\r\n[  1.995262ms,  2.454708ms) 33\r\n[  2.454708ms,  3.019951ms) 46\r\n[  3.019951ms,  3.715352ms) 45\r\n[  3.715352ms,  4.570881ms) 58\r\n[  4.570881ms,  5.623413ms) 74\r\n[  5.623413ms,  6.918309ms) 64\r\n[  6.918309ms,   8.51138ms) 92\r\n[   8.51138ms, 10.471285ms) 99\r\n[ 10.471285ms, 12.882495ms) 134\r\n[ 12.882495ms, 15.848931ms) 165\r\n[ 15.848931ms, 19.498445ms) 208\r\n[ 19.498445ms, 23.988329ms) 257\r\n[ 23.988329ms, 29.512092ms) 255\r\n[ 29.512092ms, 36.307805ms) 177\r\n```\r\n\r\nWhen run with cl/25155/3, the execution trace shows all Ps running their gcBgMarkWorker for about 10ms, then a flurry of mutator activity, then another 10–20ms of all Ps running gcBgMarkWorker.\r\n\r\n\u003cimg width=\"1511\" alt=\"screen shot 2016-07-26 at 5 48 07 pm\" src=\"https://cloud.githubusercontent.com/assets/230685/17160333/1faf19ba-5359-11e6-86a8-624d9c014824.png\"\u003e\r\n\r\n```\r\ngo run ../.../github.com/aclements/go-gcbench/gcbench/progs/rpc.go -trace /tmp/trace.bin25155 -benchtime 10s)\r\nBenchmarkRPC/reqs-per-sec:10000/ballast:64MB/gomaxprocs:4\r\n1\r\n11.0 GCs/op\r\n1.08 GCs/sec\r\n39000 95%ile-ns/sweepTerm\r\n260000 95%ile-ns/markTerm\r\n484 MB-marked/CPU/sec\r\n-0.0328 95%ile-heap-overshoot\r\n-0.297 5%ile-heap-overshoot\r\n0.316 95%ile-CPU-util\r\n9726 reqs/sec\r\nWarning: -0.297 5%ile-heap-overshoot \u003c -0.200\r\n2016/07/26 17:30:47 cleaning up client\r\n2016/07/26 17:30:47 closing 182 connections\r\nclient-measured request latency:\r\n[    13.803µs,    16.982µs) 1\r\n[    16.982µs,    20.892µs) 0\r\n[    20.892µs,    25.703µs) 0\r\n[    25.703µs,    31.622µs) 0\r\n[    31.622µs,    38.904µs) 9\r\n[    38.904µs,    47.863µs) 2503\r\n[    47.863µs,    58.884µs) 32406\r\n[    58.884µs,    72.443µs) 24280\r\n[    72.443µs,    89.125µs) 17620\r\n[    89.125µs,   109.647µs) 10894\r\n[   109.647µs,   134.896µs) 5123\r\n[   134.896µs,   165.958µs) 1744\r\n[   165.958µs,   204.173µs) 387\r\n[   204.173µs,   251.188µs) 129\r\n[   251.188µs,   309.029µs) 92\r\n[   309.029µs,   380.189µs) 73\r\n[   380.189µs,   467.735µs) 48\r\n[   467.735µs,   575.439µs) 72\r\n[   575.439µs,   707.945µs) 60\r\n[   707.945µs,   870.963µs) 58\r\n[   870.963µs,  1.071519ms) 34\r\n[  1.071519ms,  1.318256ms) 44\r\n[  1.318256ms,   1.62181ms) 77\r\n[   1.62181ms,  1.995262ms) 92\r\n[  1.995262ms,  2.454708ms) 107\r\n[  2.454708ms,  3.019951ms) 94\r\n[  3.019951ms,  3.715352ms) 98\r\n[  3.715352ms,  4.570881ms) 109\r\n[  4.570881ms,  5.623413ms) 125\r\n[  5.623413ms,  6.918309ms) 211\r\n[  6.918309ms,   8.51138ms) 231\r\n[   8.51138ms, 10.471285ms) 183\r\n[ 10.471285ms, 12.882495ms) 215\r\n[ 12.882495ms, 15.848931ms) 131\r\n[ 15.848931ms, 19.498445ms) 44\r\n```\r\n\r\ncl/25155/3 is very helpful for my production application, I'd love to see it merged for Go 1.7.\r\n\r\n---\r\n\r\n\u003e 1MB per _millisecond_. :) But, yes, this is about right and splitting work up into 100µs chunks is generally pretty reasonable.\r\n\r\nWhoops, yes! Work segments of 100µs sound good.\r\n\r\nI'm surprised that the gcBgMarkWorker goroutines are able to consume all Ps for 10ms at a time—and possibly longer, the cl/25155/3 screenshot at 1880–1890ms shows a non-zero run queue while all 4 Ps continue to run their gcBgMarkWorkers for more than 10ms. I know you have CL 24706 to change this to 1ms, which should help. A delay of 1ms is much less noticeable in most apps than one of 10ms, but it's still a constant delay that's not under the user's control.\r\n\r\nThe runtime reserves 25% of CPU time for the GC; does it make sense to reserve 25% for the application, preventing the GC from using more than 75%?\r\n\r\nHere's the execution trace of cl/25155/3 with cl/24706/1 cherry-picked on top. Of the four Ps, three of them alternate between running gcBgMarkWorkers for short periods, and running mutator code. It attenuates the latency mode near 10ms by a factor of around 100–1000, all but eliminating it (although there's now a similarly-shaped lump in the response time population near 1ms).\r\n\r\n\u003cimg width=\"1513\" alt=\"screen shot 2016-07-26 at 6 14 40 pm\" src=\"https://cloud.githubusercontent.com/assets/230685/17160814/d6772220-535c-11e6-83c8-7ab052690526.png\"\u003e\r\n\r\n```\r\ngo run .../github.com/aclements/go-gcbench/gcbench/progs/rpc.go -trace /tmp/trace.bin.25155.24706 -benchtime 10s\r\nBenchmarkRPC/reqs-per-sec:10000/ballast:64MB/gomaxprocs:4\r\n1\r\n11.0 GCs/op\r\n1.08 GCs/sec\r\n25000 95%ile-ns/sweepTerm\r\n100000 95%ile-ns/markTerm\r\n515 MB-marked/CPU/sec\r\n-0.0182 95%ile-heap-overshoot\r\n-0.320 5%ile-heap-overshoot\r\n0.315 95%ile-CPU-util\r\n9724 reqs/sec\r\nWarning: -0.320 5%ile-heap-overshoot \u003c -0.200\r\n2016/07/26 18:12:50 cleaning up client\r\n2016/07/26 18:12:50 closing 18 connections\r\nclient-measured request latency:\r\n[    31.622µs,    38.904µs) 10\r\n[    38.904µs,    47.863µs) 2700\r\n[    47.863µs,    58.884µs) 31665\r\n[    58.884µs,    72.443µs) 25215\r\n[    72.443µs,    89.125µs) 17765\r\n[    89.125µs,   109.647µs) 11147\r\n[   109.647µs,   134.896µs) 5184\r\n[   134.896µs,   165.958µs) 1724\r\n[   165.958µs,   204.173µs) 417\r\n[   204.173µs,   251.188µs) 185\r\n[   251.188µs,   309.029µs) 159\r\n[   309.029µs,   380.189µs) 157\r\n[   380.189µs,   467.735µs) 132\r\n[   467.735µs,   575.439µs) 145\r\n[   575.439µs,   707.945µs) 158\r\n[   707.945µs,   870.963µs) 165\r\n[   870.963µs,  1.071519ms) 170\r\n[  1.071519ms,  1.318256ms) 121\r\n[  1.318256ms,   1.62181ms) 18\r\n[   1.62181ms,  1.995262ms) 5\r\n[  1.995262ms,  2.454708ms) 6\r\n[  2.454708ms,  3.019951ms) 0\r\n[  3.019951ms,  3.715352ms) 0\r\n[  3.715352ms,  4.570881ms) 0\r\n[  4.570881ms,  5.623413ms) 0\r\n[  5.623413ms,  6.918309ms) 0\r\n[  6.918309ms,   8.51138ms) 0\r\n[   8.51138ms, 10.471285ms) 0\r\n[ 10.471285ms, 12.882495ms) 1\r\n```\r\n",
	"user": {
		"login": "rhysh",
		"id": 230685,
		"type": "User",
		"site_admin": false
	},
	"created_at": "2016-07-27T01:33:42Z",
	"updated_at": "2016-07-27T01:33:42Z"
}
