{
	"id": 240830472,
	"body": "CPU:\r\n\r\n```\r\n(pprof) top 20  \r\n2.18s of 2.24s total (97.32%)  \r\nDropped 13 nodes (cum \u003c= 0.01s)  \r\nShowing top 20 nodes out of 42 (cum \u003e= 0.02s)  \r\n      flat  flat%   sum%        cum   cum%  \r\n     0.45s 20.09% 20.09%      0.46s 20.54%  bufio.(*Reader).ReadRune  \r\n     0.38s 16.96% 37.05%      0.68s 30.36%  bytes.(*Buffer).WriteByte  \r\n     0.30s 13.39% 50.45%      0.30s 13.39%  bytes.(*Buffer).grow  \r\n     0.22s  9.82% 60.27%      0.29s 12.95%  runtime.mallocgc  \r\n     0.19s  8.48% 68.75%      0.63s 28.12%  encoding/csv.(*Reader).readRune  \r\n     0.15s  6.70% 75.45%      1.63s 72.77%  encoding/csv.(*Reader).parseField  \r\n     0.10s  4.46% 79.91%      0.78s 34.82%  bytes.(*Buffer).WriteRune  \r\n     0.08s  3.57% 83.48%      2.14s 95.54%  encoding/csv.(*Reader).parseRecord  \r\n     0.06s  2.68% 86.16%      0.06s  2.68%  bytes.(*Buffer).Truncate  \r\n     0.05s  2.23% 88.39%      0.28s 12.50%  runtime.rawstringtmp  \r\n     0.04s  1.79% 90.18%      0.33s 14.73%  runtime.slicebytetostring  \r\n     0.03s  1.34% 91.52%      0.03s  1.34%  runtime.memclr  \r\n     0.02s  0.89% 92.41%      2.18s 97.32%  csv_perf.BenchmarkCSV  \r\n     0.02s  0.89% 93.30%      2.16s 96.43%  encoding/csv.(*Reader).Read  \r\n     0.02s  0.89% 94.20%      0.02s  0.89%  runtime.(*mspan).countFree  \r\n     0.02s  0.89% 95.09%      0.02s  0.89%  runtime.heapBitsSetType  \r\n     0.02s  0.89% 95.98%      0.23s 10.27%  runtime.rawstring  \r\n     0.01s  0.45% 96.43%      0.07s  3.12%  bytes.(*Buffer).Reset  \r\n     0.01s  0.45% 96.88%      0.02s  0.89%  runtime.lock  \r\n     0.01s  0.45% 97.32%      0.02s  0.89%  runtime.scanblock  \r\n\r\n\r\n(pprof) top --cum 20  \r\n2.09s of 2.24s total (93.30%)  \r\nDropped 13 nodes (cum \u003c= 0.01s)  \r\nShowing top 20 nodes out of 42 (cum \u003e= 0.06s)  \r\n      flat  flat%   sum%        cum   cum%  \r\n         0     0%     0%      2.23s 99.55%  runtime.goexit  \r\n     0.02s  0.89%  0.89%      2.18s 97.32%  csv_perf.BenchmarkCSV  \r\n         0     0%  0.89%      2.18s 97.32%  testing.(*B).run1.func1  \r\n         0     0%  0.89%      2.18s 97.32%  testing.(*B).runN  \r\n     0.02s  0.89%  1.79%      2.16s 96.43%  encoding/csv.(*Reader).Read  \r\n     0.08s  3.57%  5.36%      2.14s 95.54%  encoding/csv.(*Reader).parseRecord  \r\n     0.15s  6.70% 12.05%      1.63s 72.77%  encoding/csv.(*Reader).parseField  \r\n     0.10s  4.46% 16.52%      0.78s 34.82%  bytes.(*Buffer).WriteRune  \r\n     0.38s 16.96% 33.48%      0.68s 30.36%  bytes.(*Buffer).WriteByte  \r\n     0.19s  8.48% 41.96%      0.63s 28.12%  encoding/csv.(*Reader).readRune  \r\n     0.45s 20.09% 62.05%      0.46s 20.54%  bufio.(*Reader).ReadRune  \r\n     0.04s  1.79% 63.84%      0.33s 14.73%  runtime.slicebytetostring  \r\n     0.30s 13.39% 77.23%      0.30s 13.39%  bytes.(*Buffer).grow  \r\n     0.22s  9.82% 87.05%      0.29s 12.95%  runtime.mallocgc  \r\n     0.05s  2.23% 89.29%      0.28s 12.50%  runtime.rawstringtmp  \r\n     0.02s  0.89% 90.18%      0.23s 10.27%  runtime.rawstring  \r\n         0     0% 90.18%      0.08s  3.57%  runtime.makeslice  \r\n     0.01s  0.45% 90.62%      0.07s  3.12%  bytes.(*Buffer).Reset  \r\n         0     0% 90.62%      0.07s  3.12%  runtime.systemstack  \r\n     0.06s  2.68% 93.30%      0.06s  2.68%  bytes.(*Buffer).Truncate  \r\n```\r\n\r\nMemory:\r\n\r\n```\r\n(pprof) top 30\r\n917.56MB of 917.56MB total (  100%)\r\n      flat  flat%   sum%        cum   cum%\r\n  917.56MB   100%   100%   917.56MB   100%  encoding/csv.(*Reader).parseRecord\r\n         0     0%   100%   917.56MB   100%  csv_perf.BenchmarkCSV\r\n         0     0%   100%   917.56MB   100%  encoding/csv.(*Reader).Read\r\n         0     0%   100%   917.56MB   100%  runtime.goexit\r\n         0     0%   100%   783.55MB 85.40%  testing.(*B).launch\r\n         0     0%   100%   134.01MB 14.60%  testing.(*B).run1.func1\r\n         0     0%   100%   917.56MB   100%  testing.(*B).runN\r\n(pprof) list parseRecord\r\nTotal: 917.56MB\r\nROUTINE ======================== encoding/csv.(*Reader).parseRecord in /home/bradfitz/go/src/encoding/csv/reader.go\r\n  917.56MB   917.56MB (flat, cum)   100% of Total\r\n         .          .    238:           haveField, delim, err := r.parseField()\r\n         .          .    239:           if haveField {\r\n         .          .    240:                   // If FieldsPerRecord is greater than 0 we can assume the final\r\n         .          .    241:                   // length of fields to be equal to FieldsPerRecord.\r\n         .          .    242:                   if r.FieldsPerRecord \u003e 0 \u0026\u0026 fields == nil {\r\n  543.55MB   543.55MB    243:                           fields = make([]string, 0, r.FieldsPerRecord)\r\n         .          .    244:                   }\r\n  374.01MB   374.01MB    245:                   fields = append(fields, r.field.String())\r\n         .          .    246:           }\r\n         .          .    247:           if delim == '\\n' || err == io.EOF {\r\n         .          .    248:                   return fields, err\r\n         .          .    249:           } else if err != nil {\r\n         .          .    250:                   return nil, err\r\n```\r\n\r\nWe probably can't do much about the slice per row, but we could probably add a interned string table cache to *Reader, keeping an LRU of the most recent N rows. Maybe per-column. And maybe not a map, but just a window of the past N (3, 5?) values per column.\r\n\r\nYou would have to take care of keeping the cost of that string interning mechanism cheaper than the savings from reduced GC.\r\n\r\nI haven't looked at the rest of the CPU profile.\r\n\r\nPeeking on bytes and doing ReadByte instead of the relatively expensive ReadRune would probably help a lot.\r\n",
	"user": {
		"login": "bradfitz",
		"id": 2621,
		"type": "User",
		"site_admin": false
	},
	"created_at": "2016-08-18T19:28:44Z",
	"updated_at": "2016-08-18T19:28:44Z"
}
