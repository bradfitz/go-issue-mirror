{
	"id": 144502067,
	"body": "As I understand it, staring with a 53-bit integer and then dividing it by 2-to-the-53 means that there are floating point numbers that will occur with probability zero.  Any \"random\" value less than 1/2 (2**52/2**53) will not have its LSB set, for example.  I think this is also a flaw in the original algorithm, but for a smaller set of FP numbers.\r\n\r\nI don't actually know what is officially \"right\" here because I am not an expert, but right now neither of these algorithms is doing much for me.  I recall from some earlier work that one way to do this is to take a 64-bit random number, split it into 12 and 52-bit parts, stuff 52-bits into mantissa, and then count leading zeroes on the 12-bit part to derive your exponent.  If the 12-bit part is all zero, pull more 64-bit random numbers till you get one that is not zero or till you hit (about, up to fenceposts) 1024 of them in which case you call it zero, and use the number of leading zeroes to derive your exponent.  Since you'd only do second RNG call 1 time out of 4096, this could be plenty efficient since it involves no FP ops at all (though we might hope that multiplication and division by powers of two would be very efficient).\r\n\r\nI am somewhat creeped out that both algorithms are guaranteed not to hit certain FP values.\r\n",
	"user": {
		"login": "dr2chase",
		"id": 1928999,
		"type": "User",
		"site_admin": false
	},
	"created_at": "2015-09-30T18:37:14Z",
	"updated_at": "2015-09-30T18:37:14Z"
}
