{
	"id": 171434662,
	"body": "I don't know what is happening.  The fact that it is happening for you on FreeBSD but not on GNU/Linux suggests a FreeBSD specific problem, but I don't know what it could be other than surprising behaviour of sched_yield.\r\n\r\nHere is how it is supposed to work.  There is a linked list of extra M structures to use for a callback from C to Go on a thread started by C (the structures are not needed  on threads started by Go).  That linked list starts out with one entry on it.\r\n\r\nWhen there is a callback from C to Go, the code calls needm which calls lockextra(false).  The lockextra function spins waiting for an M structure to be available.  When one is available, if it is the only one available, the code sets the needextram flag.  It then starts the callback.\r\n\r\nWhen the thread gets to Go proper, but before it actually calls the Go callback function, it checks the needextram flag.  If it is set, the thread calls newextram.  The newextram function allocates a new M structure and adds it to the list (using another call to lockextra, this time passing true).\r\n\r\nWhen the Go callback function completes, the runtime calls dropm.  This adds the M structure back on the list, using another call to lockextra(true).\r\n\r\nIf a bunch of callbacks happen simultaneously, they will all collide getting an M structure.  The first one to succeed will create a new M structure, handing it over to the next thread.  When the callback completes, the M structure will be put back on the list.\r\n\r\nSo the behaviour we are likely to see is that the first time there are a bunch of parallel callbacks, there is contention in lockextra until all the M structures are allocated.  When all the callbacks complete, the linked list will have a bunch of M structures, so there should be no more issues until there is again a bunch of even more parallel callbacks.  Is that the behaviour you see?  An initial set of collisions that resolve, followed by normal behaviour?\r\n\r\nThe parallel callbacks vying for an M can theoretically starve the callback adding a new M to the list.  This is not supposed to happen because of the call to osyield, and because getting the lock and failing to find an M to use will call usleep(1), giving time for the new M to appear.\r\n\r\nThe call to usleep does add another possibility for OS-specific differences.  The FreeBSD/AMD64 specific code looks fine to me, though.  Does your truss listing show any calls to nanosleep?",
	"user": {
		"login": "ianlancetaylor",
		"id": 3194333,
		"type": "User",
		"site_admin": false
	},
	"created_at": "2016-01-13T21:14:32Z",
	"updated_at": "2016-01-13T21:14:32Z"
}
