{
	"id": 139406627,
	"body": "I haven't looked at fmt.Scan. Permitting a decimal point for a decimal mantissa is tricky. The point of the 'p' notation is 100% lossless conversion with a fast and simple algorithm. In general that's not true anymore once a decimal point is permitted.\r\n\r\nbig.Float uses a different format: the mantissa is represented by a hex number which corresponds to the bits after (to the right) of the \"decimal\" point - that is, that mantissa value m is 0.5 \u003c= m \u003c 1.0. It's essentially used for testing (and could possibly be changed).\r\n\r\nGiven a sign s (-1, +1), a mantissa m that is simply a decimal unsigned integer, and a binary exponent b, the floating point value x is x = s * m * 2**b . No further explanation needed.\r\n\r\nThere are design decisions to be made when printing using a binary exponent: The mantissa may be scaled arbitrarily. Currently, printing simply prints the float32/float64 mantissa bits like if they were int32 or int64 bit numbers (with appropriate exponent). This requires knowing the bit size of the type to reproduce. Another option would be to always print a canonical form; for instance such that the mantissa is the smallest possible value before requiring a decimal point. That is equivalent to having no trailing 0's in the mantissa (or the mantissa being odd, except for x == 0).\r\n\r\nBut for parsing it doesn't matter.\r\n\r\nMore generally: it seems that strconv conversion routines should parse numbers that it can print.",
	"user": {
		"login": "griesemer",
		"id": 8528975,
		"type": "User",
		"site_admin": false
	},
	"created_at": "2015-09-10T23:04:02Z",
	"updated_at": "2015-09-10T23:04:02Z"
}
