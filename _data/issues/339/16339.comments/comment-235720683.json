{
	"id": 235720683,
	"body": "A thing that wasn't expressed AFAICT is, that the issue with refactoring isn't due to code size, but due to a) development velocity and b) inertia. To do a refactoring like moving `golang.org/x/net/context` to `context`, you need to guarantee atomicity over the whole codebase. As you have independent projects with independent owners, you need their approval for a change. The issue that arises is, that between filing \"pull requests\" against all projects, and getting approval from *all* projects (the merge point), lies a large amount of time (the inertia part, people need, independently, to get up and look at the change), during which all projects continue to submit code (the velocity part) creating potential merge conflicts. So during that time period, you need to basically acquire a global code-change lock, to guarantee atomicity.\r\n\r\nNow, for a large company, the issue here is mainly the velocity (as they can overcome inertia with hierarchy), the rate of submitted changes is so huge, that even with a relatively small time-frame needed to get the global approval, the holdup of development is just not tolerable. However, theoretically this could be an issue that can be overcome with tooling: You could, theoretically, have a review not for a specific set of diffs, but for \"I approve the outcome of running this tool on my codebase, as long as the tests pass\" and thus decouple the approval time from the time where the lock must be held.\r\n\r\nBut for the community at large, the issue is inertia. It is *impossible* to get global approval in any reasonable time frame. Because humans are slow, they are especially slow in the maintenance of hobby FOSS projects and they are not properly incentivised to actually merge your PR. You will also not get everyone to agree to letting a single tool manage a global change atomically as above, because that would require giving it push-access to all the things.\r\n\r\nThis is why I think this proposal is actually much more interesting for the open source community than for large companies. Because now the time frame can be *much* larger. You can essentially leave the refactored stuff lying around for half a year or so, which would be a large enough time frame even for open source developers to adopt. A pure tooling based approach can't really help.\r\n\r\n\r\nI also want to disagree with the solution of versioning for this. It's a solution only in the sense that stuff won't break. It won't actually help people adopt the new thing (plus the diamond dependency problem) . The result of changing from version n to version n+1 is, that you either have to maintain two versions for a while (say, the half-year timeframe fom above) or tolerate that a lot of projects won't benefit from bug fixes, security fixes and general improvements, because they didn't do the bump in their config. I think refactorings and breakages should be done in a continuous, gradual way for that reason; the alias solution will mean that users of your package will get improvements without needing to actually react to the refactoring right away (so you don't suffer as much from the inertia).\r\n\r\nI wasn't sure whether I like this proposal or not, in the beginning. I think I now convinced myself it's a good idea, as there is no real good alternative that solves this problem and I strongly prefer a world of gradual refactorings over a world in which we pretend SemVer works.",
	"user": {
		"login": "Merovius",
		"id": 720787,
		"type": "User",
		"site_admin": false
	},
	"reactions": {
		"total_count": 13,
		"+1": 6,
		"-1": 1,
		"heart": 5,
		"hooray": 1
	},
	"created_at": "2016-07-27T21:05:16Z",
	"updated_at": "2016-07-27T21:05:16Z"
}
