{
	"id": 231560913,
	"body": "As the OP, I applaud that strategy. I still think a specialized mechanism\nmay be needed, but it seems relatively easy to roll my own. If I supply my\nown C stacks then I don't need any fragile hooks into the go runtime or\nscheduler, just a little assembly code. So if it's still a problem\nafterward, there is an option that just requires a little effort - and I\nthink for a potentially unsafe and advanced feature that's even desirable.\n\nOn Sat, Jul 9, 2016 at 3:57 PM, Austin Clements \u003cnotifications@github.com\u003e\nwrote:\n\n\u003e Our current plan is to start by optimizing the existing cgo path and see\n\u003e how far we can get with that before we consider introducing a new mechanism\n\u003e (particularly one that could introduce new classes of bugs).\n\u003e\n\u003e I keep wondering how this cost is also impacting other areas like server\n\u003e applications with heavy UDP traffic.\n\u003e\n\u003e I'm not sure, but it might be possible to further optimize Windows system\n\u003e calls beyond the regular cgo path. Most other platforms don't use cgo for\n\u003e syscalls, and there's much less overhead. OTOH, Windows syscalls can have\n\u003e callbacks, so the generality may be necessary.\n\u003e\n\u003e â€”\n\u003e You are receiving this because you were mentioned.\n\u003e Reply to this email directly, view it on GitHub\n\u003e \u003chttps://github.com/golang/go/issues/16051#issuecomment-231560365\u003e, or mute\n\u003e the thread\n\u003e \u003chttps://github.com/notifications/unsubscribe/AABrtk08THykI6Q2OnEp9wXn7RlUcgkoks5qUCdagaJpZM4I0hlW\u003e\n\u003e .\n\u003e\n",
	"user": {
		"login": "eloff",
		"id": 27574,
		"type": "User",
		"site_admin": false
	},
	"created_at": "2016-07-09T23:12:37Z",
	"updated_at": "2016-07-09T23:12:37Z"
}
