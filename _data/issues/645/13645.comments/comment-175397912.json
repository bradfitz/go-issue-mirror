{
	"id": 175397912,
	"body": "So, @aclements, how can that happen? :-)\r\n\r\nA few thoughts, perhaps none of them useful.\r\n\r\n(1) It looks to me like there are two different p's both with gcMarkWorkerMode == gcMarkWorkerFractionalMode. That seems wrong: I thought there would be only one worker dedicated to being a fraction at any given time.\r\n\r\nIt looks like the \"we lost a race\" here would explain having two fractional workers:\r\n\r\n\tdecIfPositive := func(ptr *int64) bool {\r\n\t\tif *ptr \u003e 0 {\r\n\t\t\tif atomic.Xaddint64(ptr, -1) \u003e= 0 {\r\n\t\t\t\treturn true\r\n\t\t\t}\r\n\t\t\t// We lost a race\r\n\t\t\tatomic.Xaddint64(ptr, +1)\r\n\t\t}\r\n\t\treturn false\r\n\t}\r\n\r\nI don't see any actual harm caused by having two fractional workers in the code. Eventually one will die and not be replaced (until the next race). But still it seems scary and could be avoided with a Cas if we understood how it explained real damage.\r\n\r\n(2) gcphase is 0. Why are there any fractional workers in that case? The GC that kicked off the fractional workers must have finished to get to gcphase 0. How did it finish with the fractional workers still thinking they should run?\r\n\r\n(3) I see assignments that set _p_.gcMarkWorkerMode but nothing that clears it. Also gcMarkWorkerDedicatedMode == 0, which is a little odd for distinguishing \"not a worker\" from \"a worker\". But maybe code only looks at that field if it knows it is a worker, in which case the two p's with fractional mode could both be stale, with neither actually being a worker.\r\n\r\n(4) All cgocalls lock the goroutine to the thread for the duration of the call, in case of cgo callbacks. When a goroutine is locked to a thread, that thread bails out of func schedule very early. It does not even reach the code thinking about being a GC worker. It's possible that the thread ran a GC worker earlier, before being locked, but that worker is preempted if we're doing the cgo call. And then the worker is attached to the p, which will be released elsewhere while the cgo call is blocked. And the GC finished.\r\n\r\n(5) The stack trace doesn't show us where the cgo call goroutine is blocked. It will show the entersyscall information until gp.syscallsp is cleared after the goroutine is cleared to run. But I don't see any way it can block during entersyscall, so it must be blocked in exitsyscall. \r\n\r\n(6) System stacks would be nice. Since this seems to happen mainly on Windows, I wonder if we can adapt os1_windows.go's profileloop1/profilem into something that will give us the same thread stacks we now can get on Unix.",
	"user": {
		"login": "rsc",
		"id": 104030,
		"type": "User",
		"site_admin": false
	},
	"created_at": "2016-01-27T04:54:53Z",
	"updated_at": "2016-01-27T04:55:31Z"
}
