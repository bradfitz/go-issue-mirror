{
	"id": 246965939,
	"body": "So, how about this:\r\n\r\n- timers and network IO are managed by the runtime and don't result in `_Gsyscall` goroutines (except for the system goroutines which should be excluded).\r\n- cgocalls can include syscalls which cannot be tracked. as a result these syscalls are always counted.\r\n- Applications accessing the network through cgo (which hides the syscalls) should be rare.\r\n- other syscalls generally result in CPU load and thus should be included.\r\n\r\nSo unless you are heavily using something like `gopkg.in/fsnotify.v1` `NumActiveGoroutine` should be a decent approximation of the actual work load.\r\n\r\nIncluding `_Gsyscall` should be a good starting point for `NumActiveGoroutine`. \r\nThe runtime could be extended to record the called syscall in G.\r\nThen syscall package could be extended with a list of syscalls that result in some form of _idling_. \r\nGiven these changes, `NumActiveGoroutine` can decide whether to consider the goroutine active or not. Syscalls called from cgo are still hidden in this senario.\r\n\r\nRemember, it is not my goal to find an accurate estimation of the CPU utilisation. Instead it is my goal to find a good-enough estimation of the application utilisation. I included a excerpt from _Site Reliability Engineering, How Google Runs Production Systems_ which seems to suggest that Google uses a similar metric/approach.\r\n\r\n---\r\n\r\n#### [Site Reliability Engineering, How Google Runs Production Systems][sre] - p. 366\r\n\r\n\u003e The utilization signals we use are based on the state local to the task (since the goal of the signals is to protect the task) and we have implementations for various signals. The most generally useful signal is based on the “load” in the process, which is determined using a system we call executor load average .\r\n\u003e \r\n\u003e To find the executor load average, we count the number of active threads in the process. In this case, “active” refers to threads that are currently running or ready to run and waiting for a free processor. We smooth this value with exponential decay and begin rejecting requests as the number of active threads grows beyond the number of processors available to the task. That means that an incoming request that has a very large fan-out (i.e., one that schedules a burst of a very large number of short-lived operations) will cause the load to spike very briefly, but the smoothing will mostly swallow that spike. However, if the operations are not short-lived (i.e., the load increases and remains high for a significant amount of time), the task will start rejecting requests.\r\n\r\n  [sre]: https://play.google.com/store/books/details?id=tYrPCwAAQBAJ",
	"user": {
		"login": "fd",
		"id": 591,
		"type": "User",
		"site_admin": false
	},
	"created_at": "2016-09-14T10:06:53Z",
	"updated_at": "2016-09-14T10:06:53Z"
}
