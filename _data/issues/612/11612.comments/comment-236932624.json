{
	"id": 236932624,
	"body": "\u003e This got much much worse with the new SSA backend. Even the 500 lines example requires gigabytes of memory to be compiled\r\n\r\nAFAICT there are only 2 variables ('r_INT' and 'samples') for SSA construction in the code snippet.\r\nAssuming it has 10k basic blocks (which is hopefully an exaggeration for the 500 line version) and it requires 2GB (lower bound for the word 'gigabytes'), then this would mean 100kB memory per variable per basic block.\r\nTo me this seems, that something is going very wrong.\r\nIt should only be a few bytes per variable per block to remember the current binding of the variable.\r\nSeveral thousand basic blocks should be no issue at all for the algorithm.\r\n\r\nSome statistics for compiling the code snippet would be very interesting:\r\nHow many variables are there (considered for SSA construction)?\r\nHow many basic blocks?\r\nHow is getting values from other basic blocks handled?\r\nAs described in the paper or is there some multi-pass handling?\r\nWhen are useless Phis eliminated -- on the fly while looking up bindings in other blocks or afterwards?\r\n\r\nDisclaimer:\r\nUniQP and me are two of the authors of the paper.\r\nOur compiler framework (libfirm) uses this construction algorithm for a long time now.",
	"user": {
		"login": "chmallon",
		"id": 20772248,
		"type": "User",
		"site_admin": false
	},
	"created_at": "2016-08-02T15:02:27Z",
	"updated_at": "2016-08-02T15:02:27Z"
}
