{
	"id": 174096614,
	"number": 16930,
	"state": "open",
	"title": "runtime: make the scavenger more prompt",
	"body": "Currently, there's a lag of at least five minutes (and potentially much longer) between the Go heap size shrinking and the process' RSS shrinking. This is done to amortize the cost of releasing and re-acquiring system memory, but has several downsides:\r\n\r\n1. It's bad for memory-constrained environments, whether that constraint is 10MB or 100GB, since it makes it basically impossible to respond to resource changes by shrinking the heap. This is particularly noticeable in server environments that allow temporarily exceeding a soft limit, since it turns this soft limit into a hard limit.\r\n\r\n2. It prevents using memory for other useful purposes. There's no such thing as \"unused memory\". Memory not used by an application will be used by the OS for the buffer cache or the zero page cache, and free memory gives the OS the flexibility to perform optimization like transparent huge pages or NUMA migration. In the mobile sphere, this is particularly noticeable to the user, since it means less space for application and resource caching, which directly affects user experience.\r\n\r\n3. Finally, it's confusing. It's clear from questions on golang-nuts and elsewhere that people expect their RSS to track their heap size and, in particular, their heap profiles.\r\n\r\nI believe we should make the scavenger release memory promptly and aggressively.\r\n\r\nI believe we can do this without significant overhead by improving the design of the scavenger. Currently the scavenger is careful to recycle spans that have been unused for more than five minutes. This is largely wasted effort because *virtual memory is fungible*: there's a slight TLB locality boost to retaining very recently used memory (on the order of a few megabytes), but beyond this it doesn't matter what unused pages we return to the OS. The inflexibility of the scavenger has several downsides. Primarily, it requires many system calls to release sparse unused regions of memory, and these system calls have a very high per-call cost because the OS needs to do remote TLB invalidation. This cost also grows with the number of CPUs. It can also needlessly delay freeing memory because coalescing two neighboring free spans takes the most recent \"used\" time of the two.\r\n\r\nI propose separating the concerns of *how many* pages to release from *which* pages to release.\r\n\r\nWhich pages to release should be based on minimizing the number of `sysUnused` calls (`madvise` on Linux). Roughly, releasing *n* pages should attempt to release an *n* page span and if no spans *n* pages or larger are on the free list, it should release as few smaller spans as possible. There are many algorithms that satisfy this outline, and I suspect the details don't matter. It would be reasonable to adopt the exact algorithm [used by tcmalloc](https://github.com/gperftools/gperftools/blob/41aca070e85258d9d47b0ac47f5eddece8bf45ba/src/page_heap.cc#L478), since that has been field-tested. We should preferentially release spans from the end of the free lists, since those have been least recently used and have the least preference for being reused.\r\n\r\nHow many pages to release is a harder question, but by separating these concerns we have the flexibility to choose a good answer. For example, the current policy can be expressed as retaining `max(HeapInUse over the past 5 minutes)`. The \"right\" answer depends on the costs of releasing and re-acquiring memory, the future size of the heap, and the relative CPU versus memory costs we're willing to incur. Because of the \"sawtooth\" behavior of GC, we do know something about the future size of the heap, at least: the heap will grow to the heap goal in the near future, and often that heap goal is in a rough steady state. Hence, as a simple heuristic, I propose we use the heap goal times a \"steady state variance\" factor, with some hysteresis to retain cost amortization in case garbage collections are happening rapidly:\r\n\r\n```\r\nretain = C * max(current heap goal, max({heap goals of GCs over the past T seconds}))\r\nC = 1 + Îµ = 1.1\r\nT = 10 seconds\r\n```\r\n\r\n/cc @matloob @RLH\r\n",
	"user": {
		"login": "aclements",
		"id": 2688315,
		"type": "User",
		"site_admin": false
	},
	"labels": [
		{
			"name": "NeedsFix"
		}
	],
	"comments": 0,
	"created_at": "2016-08-30T18:53:45Z",
	"updated_at": "2016-10-11T22:13:37Z",
	"milestone": {
		"id": 1709363,
		"number": 38,
		"title": "Go1.8"
	}
}
