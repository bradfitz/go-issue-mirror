{
	"id": 127634787,
	"body": "The downside is that every mark must read the span mark, which admittedly\nwill probably be in the cache. I would have to see numbers before I'd buy\ninto the blind mark is faster than read compare mark.\n\nOn Sat, Aug 1, 2015 at 12:38 PM, Austin Clements \u003cnotifications@github.com\u003e\nwrote:\n\n\u003e Objects larger than 32K are handled by a large object allocator\n\u003e (largeAlloc) because they fall outside the size classes for which there are\n\u003e span caches. Currently, in order to control heap growth, the large object\n\u003e allocator sweeps until it reclaims the number of pages being allocated\n\u003e before performing the allocation (mHeap_Alloc_m -\u003e mHeap_ReclaimList). This\n\u003e path is also taken when growing the heap.\n\u003e\n\u003e However, this process can be quite expensive. It first tries sweeping\n\u003e large object spans. *If* this succeeds, the process is fairly efficient;\n\u003e it may require looking at a large number of spans that don't have a free\n\u003e object, but it's not clear if it's possible to eliminate this linear\n\u003e constant. However, empirically, this often fails. This may simply be\n\u003e because earlier large allocations swept spans that were larger than they\n\u003e were allocating and they didn't keep track of this credit. In this case, it\n\u003e falls back to sweeping small object spans until it's able to free enough\n\u003e (potentially non-contiguous) pages that way. As a result of this, in the\n\u003e x/benchmarks garbage benchmark, the large object sweeper winds up sweeping\n\u003e ~30 times more bytes than it's trying to allocate.\n\u003e\n\u003e I believe we can eliminate this entire mechanism if, during marking, the\n\u003e garbage collector also keeps a per span \"super mark\" that is set if any\n\u003e objects in the span are marked. At the point where we would set this, we\n\u003e already have the span and, assuming we're willing to dedicate a byte per\n\u003e span for this, it can be set with a blind (possibly even non-temporal)\n\u003e write. At the end of GC, after mark termination, we can immediately free\n\u003e these spans (both large object spans and small object spans with no\n\u003e reachable objects). It takes roughly 1ms per heap GB to walk the span list,\n\u003e so even assuming a little more overhead for adding free spans to span\n\u003e lists, it seems very likely this would take less time than we currently\n\u003e spend sweeping these spans. This is also trivially parallelizable, and we\n\u003e probably have to do this walk anyway (#11484\n\u003e \u003chttps://github.com/golang/go/issues/11484\u003e). Additionally, this will\n\u003e reduce load on concurrent sweep and coalesce neighboring spans much\n\u003e earlier, making larger regions of memory available for large object\n\u003e allocation immediately.\n\u003e\n\u003e This idea is based on various (mostly pairwise) discussions between\n\u003e myself, @RLH \u003chttps://github.com/RLH\u003e, @rsc \u003chttps://github.com/rsc\u003e, and\n\u003e @dvyukov \u003chttps://github.com/dvyukov\u003e.\n\u003e\n\u003e â€”\n\u003e Reply to this email directly or view it on GitHub\n\u003e \u003chttps://github.com/golang/go/issues/11979\u003e.\n\u003e\n",
	"user": {
		"login": "RLH",
		"id": 972447,
		"type": "User",
		"site_admin": false
	},
	"created_at": "2015-08-04T14:37:06Z",
	"updated_at": "2015-08-04T14:37:06Z"
}
