{
	"id": 253638894,
	"body": "\u003e I don't see why this would help. GC pause times are close to 0 and getting closer. It's not the pauses that are the problem, it's the CPU taken away from the compiler during the concurrent phase.\r\n\r\nI see.  I said \"GC pause times\" just because that's the only time duration that I could see in package runtime.MemStats or runtime/debug.GCStats, and I naively assumed it somehow represented total GC overhead.  I guess it actually means only STW time?\r\n\r\nIs there a good way to measure CPU cost from the concurrent phase? Also, currently I think we only measure per-phase wallclock time. I wonder if we need to measure per-phase CPU-seconds instead, since the GC is concurrent (and possibly the compiler itself will be too, in the future).\r\n\r\n\u003e  I'm not sure what you mean by \"live memory the FE has left\" since live memory isn't something that's left, but I don't think this is about measurement anyway.\r\n\r\nI meant (for example) to make an explicit runtime.GC() call at the end of the frontend phases and record the runtime.MemStats.Heap{Alloc,Objects} values.  The hypothesis being that 1) they represent how much data the FE has allocated that will continue to remain live throughout the BE phases, and 2) improving those numbers should reduce the amount of GC work necessary during the BE phases.  Is that sound, or is my model of GC effects too naive?",
	"user": {
		"login": "mdempsky",
		"id": 38349,
		"type": "User",
		"site_admin": false
	},
	"created_at": "2016-10-13T21:06:35Z",
	"updated_at": "2016-10-13T21:07:03Z"
}
