{
	"id": 118027081,
	"body": "I like the imagery of a drive by goroutine a lot, the literature also uses\nthe boring term barging. To put a number on the cost of fair locks Doug Lea\n(http://gee.cs.oswego.edu/dl/papers/aqs.pdf) reports a 1 to 2 orders of\nmagnitude slowdown over locks that allow barging. They\n(java.util.concurrency circa 2004) also stepped back from a definition of\nfair to be less than a strict FIFO.\nIn the intervening decade since that paper Hannes Payer has done some\npromising work on queues with even weaker semantics such as a allowing a\npop to return some value near, as opposed to at, the front of the queue.\nI believe we can build fairness on top of weaker unfair semantics so not\ncooking the stronger semantics into Go is the way forward.\n\nOn Thu, Jul 2, 2015 at 7:52 AM, Dmitry Vyukov \u003cnotifications@github.com\u003e\nwrote:\n\n\u003e You seem to assume that the entity that benefits from reduced latency is a\n\u003e goroutine only. This is true when a goroutine services a request and needs\n\u003e to acquire some aux resource (e.g. a database connection). But this is not\n\u003e true for all producer-consumer/pipelining scenarios, where the entity that\n\u003e benefits from reduced latency is a *message* in a chan. Today messages in\n\u003e chans are serviced strictly FIFO and with minimal latency: the next\n\u003e *running* goroutine picks up the first message in a chan. What you\n\u003e propose improves the database connection pool scenario but equally worsens\n\u003e the producer-consumer scenario. Because under your proposal we handoff the\n\u003e first message in the chan to a goroutine that will run who-knows-when, and\n\u003e a goroutine that drives by the chan next moment either blocks or services\n\u003e the second message ahead of the first one. If we switch the implementation\n\u003e we will start receiving complaints about the other scenarios.\n\u003e Also sase synchronization primitives is usually the wrong level for\n\u003e fairness. They can't ensure user-perceived fairness. Consider that to\n\u003e service a request you need to do 10 DB queries. DB pool has fair\n\u003e queue, however older requests (that do 10-th query ) complete with newer\n\u003e requests (that do first query). As the result some requests can experience\n\u003e no waiting time, while others can wait for a hundred of requests in total.\n\u003e What you propose is known to significantly reduce performance due to\n\u003e requirement of lock-step scheduling order. Which becomes significantly\n\u003e worse if you add a bunch of unrelated goroutines to the mix, so that you\n\u003e have lock-step with a very long step time.\n\u003e Regarding the unnecessary wakeup, it's easy to fix. See #8900\n\u003e \u003chttps://github.com/golang/go/issues/8900\u003e.\n\u003e\n\u003e â€”\n\u003e Reply to this email directly or view it on GitHub\n\u003e \u003chttps://github.com/golang/go/issues/11506#issuecomment-118007672\u003e.\n\u003e\n",
	"user": {
		"login": "RLH",
		"id": 972447,
		"type": "User",
		"site_admin": false
	},
	"created_at": "2015-07-02T13:08:29Z",
	"updated_at": "2015-07-02T13:08:29Z"
}
