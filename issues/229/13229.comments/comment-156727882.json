{
	"id": 156727882,
	"body": "@jfcg, below 2^64, there are almost 32 million base-2 strong pseudoprimes.  Of those, 1.5 million are also base-3 strong pseudoprimes.  Of those, 131,157 are also base-5 strong pseudoprimes.  16,826 will pass M-R with bases 2,3,5 and 7.   No number below 2^64 will pass a properly written BPSW test.  Hence it is deterministic below that size.   [edit:  see the Galway/Feitsma database, also see [Pseudoprime Statistics, Tables, and Data](http://ntheory.org/pseudoprimes.html)]\r\n\r\nStrong vs. standard Lucas test:  the 1980 paper rightly points out that there is no reason *not* to use the strong test.  The pseudoprimes are not only a subset but the performance is the same or better.  Why Java chose to ignore that is beyond me, but a clue may be gained by their calling it a \"Lucas-Lehmer\" test, which is a completely different test.  This is not written by someone familiar with the literature.\r\n\r\nRe performance, on primes, a good implementation of BPSW should take 2.5 to 3.5 times the time of a single M-R test.  A practical primality test will include some trial division to very quickly weed out composites.  For under 2^64 this is probably just to 20-100, but for larger numbers it is better on average to look much further.  I use primes to 53 for 32-bit and to 89 for 64-bit, but that's a particular C implementation.  The first M-R test will cut out most of the remaining composites.  Using base-2 strong pseudoprimes as the test set is of course the worst case for BPSW as you guarantee it must run the Lucas test (which is ~1.5 - 2.5 times the cost of an M-R test).  Anyway, I cannot discuss this implementation, but BPSW ought to be much faster than M-R with 40 bases.\r\n\r\nFor more on performance, under 64-bit the fastest solutions (that I am aware of) involve tuning small numbers, tuning the trial division pre-tests, then using hashed Miller-Rabin for 32-bit, and either hashed-Miller-Rabin or BPSW above that.  For native integers they also use M-R and Lucas tests using Montgomery math and snippets of assembly, but I assume that is far beyond the scope of this.\r\n\r\nI have a BPSW implementation for Perl6 using MoarVM.  It is 4-20x faster than the current one for large numbers (10^50 - 10^8000).  It also removes some known counterexamples (they don't use random bases).  This is not directly comparable (the code in question uses C+libtommath and lives in the VM internals), but gives some idea.\r\n\r\nMost of the literature is linked on the [Wikipedia page](https://en.wikipedia.org/wiki/Baillie%E2%80%93PSW_primality_test).  The paper by Baillie and Wagstaff (October 1980) is IMO the definitive paper (the July 1980 paper cites it, but got published first).  Nicely's site is nice but has a few misleading comments (e.g. the trial division step is not part of BPSW, and his comments on the extra-strong Lucas test are not right).  I would also recommend [Pinch 1993](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.33.4409) which is one reason all the math programs switched to BPSW in the 90s.  Looking at [Nicely's GMP pseudoprimes page](http://www.trnicely.net/misc/mpzspsp.html) is also interesting.\r\n\r\nThe main problem I've had trying to discuss BPSW with people who don't know the field is the \"what is the exact error bound!\" question.  The second is a lack of understanding of the difference between fixed and random bases, but that's not an issue here.  For error bounds, the best we can do with BPSW as a guarantee is 1/4 * 4/15 (M-R 2 plus strong Lucas) or 1/4 * 1/8 (M-R 2 plus ES Lucas).  It should be obvious, given that we know there are no counterexamples below 2^64 and haven't seen one above, that this error bound is ludicrously conservative.  However there isn't a strong statement we can give.  Strong pseudoprimes and strong Lucas pseudoprimes are less dense as the input size increases, and the tests are anti-correlated so we would expect them to be hard to find once past the small numbers.\r\n\r\nIf one is very uptight about correctness, I would suggest separating out these cases:\r\n\r\n  - below 2^64, do whatever is best for performance and gives completely correct results.  This is where a lot of users will spend time calling you in loops.  BPSW is one way to get correct results, so is deterministic M-R, so is hashed deterministic M-R.\r\n  - See [Sorenson and Webster, Sep 2015](http://arxiv.org/abs/1509.00864) for deterministic M-R to 33170 44064 67988 73859 61981 (over 2^81).  You can call it directly or first call BPSW then if that is true and the input is below the threshold, call the 12 extra M-R tests to get a deterministic correct answer).\r\n  - BPSW plus a few random-base M-R tests.  BPSW gives you the result that anything that passed your test would have also passed a number of other programs.  The extra random-base M-R tests will give you extra warm fuzzies, not take too long if there are only a few (e.g. 2 to 5), and defeat the nefarious NSA agents who are holding onto the secret (your variant) BPSW counterexamples.",
	"user": {
		"login": "danaj",
		"id": 125502,
		"type": "User",
		"site_admin": false
	},
	"created_at": "2015-11-14T17:57:08Z",
	"updated_at": "2015-11-14T17:58:12Z"
}
