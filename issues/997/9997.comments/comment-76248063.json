{
	"id": 76248063,
	"body": "It's a pretty bog standard Ubuntu 14/04 config with the Nvidia 340 binary drivers. The examples used to work when I tested right after Go 1.4 got released, but not anymore, and I really couldn't say what has changed on my system since then.\r\n\r\nAnyhow, when I debugged this issue, EGL returned visual id 0x27 while the default is 0x21, as reported by xdpyinfo:\r\n\r\n      number of visuals:    228\r\n      default visual id:  0x21\r\n      visual:\r\n        visual id:    0x21\r\n        class:    TrueColor\r\n        depth:    24 planes\r\n        available colormap entries:    256 per subfield\r\n        red, green, blue masks:    0xff0000, 0xff00, 0xff\r\n        significant bits in color specification:    8 bits\r\n    (...)\r\n      visual:\r\n        visual id:    0x27\r\n        class:    TrueColor\r\n        depth:    24 planes\r\n        available colormap entries:    256 per subfield\r\n        red, green, blue masks:    0xff0000, 0xff00, 0xff\r\n        significant bits in color specification:    8 bits\r\n\r\nThere's probably more to it, but they look the same.\r\n\r\nAdding the colormap is straightforward, but I ran into another issue with the basic example that crashes somewhere in gl.DrawArrays(), so I want to investigate this further before submitting a patch (I don't see how adding a true color colormap could cause this, but one never knows). The sprite example runs fine though.",
	"user": {
		"login": "db47h",
		"id": 879556,
		"type": "User",
		"site_admin": false
	},
	"created_at": "2015-02-26T19:22:00Z",
	"updated_at": "2015-02-27T15:48:22Z"
}
