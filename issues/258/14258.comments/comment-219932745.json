{
	"id": 219932745,
	"body": "Some optimizations landed. Others didn't make the code freeze deadline. @klauspost would probably know better than me what's out that he'd still like to bring over from https://github.com/klauspost/compress\r\n\r\nRe-balancing, in terms of tweaking what parameter settings correspond to \"compression level == 6\", didn't happen, but when compared to Go 1.6, I believe that compression is still generally faster on GOARCH=amd64 at the default setting. I don't have any numbers on me right now.\r\n\r\nAlso, \"compression level == 1\" aka \"best speed\" now uses the Snappy algorithm, for higher throughput but larger encoded size. That encoding size can come down with further algorithmic changes, but there was a correctness bug found in the fancier algorithm just before code freeze, so that will have to wait for Go 1.8.\r\n\r\nIssue #15622 is that compress/flate's minimum LZW-style match length increased from 3 bytes to 4 bytes, as 32-bit ops can be a lot faster. However, compressing RGB images can often want 3-byte matches, corresponding to an RGB tuple. We're still investigating how big a regression this is: whether it's \"TIFF and PNG images are consistently e.g. 10% to 20% larger\" or if it's \"some are larger, some are smaller, and it's mostly a wash, although you can always find examples where it's significantly worse\", or if it's somewhere in between. The current proposal is to re-introduce 3-byte matches for higher levels of the compression size-vs-throughput knob, although that will be more (as-yet-unwritten-and-untested) code.\r\n\r\nI don't think there are any open CLs. Please correct me if I'm wrong.",
	"user": {
		"login": "nigeltao",
		"id": 8565232,
		"type": "User",
		"site_admin": false
	},
	"created_at": "2016-05-18T06:00:34Z",
	"updated_at": "2016-05-18T06:24:45Z"
}
