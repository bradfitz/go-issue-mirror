{
	"id": 66094431,
	"body": "\u003ca id=\"c3\"\u003e\u003c/a\u003eComment 3:\n\n\u003cpre\u003eThe unrolling was mainly a demonstration of the speed difference, not the code that\nshould be implemented. I was guessing a similar approach to memcopy, small things\ninlined, large ones call some function.\n\nMain use case would be sorting and priority queues. I noticed this thing while\noptimizing Brad-s slice package \u003ca href=\"https://github.com/egonelbre/slice\"\u003ehttps://github.com/egonelbre/slice\u003c/a\u003e. I did some rough\nmeasurements and it showed that starting at 3 int64-s the unrolled swap started being\nfaster, which corresponds to the size of slice header. Of course the performance benefit\nthere is quite small, only a few percent.\n\nI tried to measure the actual effect on sorting \u003ca href=\"http://play.golang.org/p/HoBVsztPlg\"\u003ehttp://play.golang.org/p/HoBVsztPlg\u003c/a\u003e\nThe first test gave me some conflicting data:\n\nBenchmarkSortSimple         5000            667638 ns/op\nBenchmarkSortCache          5000            612834 ns/op\nBenchmarkSortUnroll         5000            685639 ns/op\nBenchmarkSortReference      5000            664638 ns/op\n\nI'm not entirely sure why the Cache version here that much faster; and why the unrolled\nversion ended up slower.\n\nA second example \u003ca href=\"http://play.golang.org/p/GWupagv5wY\"\u003ehttp://play.golang.org/p/GWupagv5wY\u003c/a\u003e gave somewhat expected results:\n\nBenchmarkSortSimple         5000            506628 ns/op\nBenchmarkSortCache          5000            484627 ns/op\nBenchmarkSortUnroll         5000            483627 ns/op\nBenchmarkSortReference      5000            478427 ns/op\n\nSo, I would have to conclude that using pointers is preferable, instead of trying to\nmake swaps faster. You would have an extra indirection while using that slice, but I'm\nnot able to figure out a really good example that involves both. So, I don't think I can\ncome up with a better real world example than the \"slice\" package; but it uses generated\ncode anyways, so it can just as easily generate the unrolled code.\n\nIt seems the major performance improvement doesn't come from the unrolling, but rather\nindexing the slice. ( \"e[i], e[j] = e[j], e[i]\" vs. \"a, b := \u0026e[i], \u0026e[j]; *a, *b = *b,\n*a\" ) So, that might be a more reasonable optimization; then again, it can be easily\ndone by hand.\u003c/pre\u003e",
	"user": {
		"login": "egonelbre",
		"id": 192964,
		"type": "User",
		"site_admin": false
	},
	"created_at": "2014-05-04T13:12:35Z",
	"updated_at": "2014-12-08T10:43:56Z"
}
