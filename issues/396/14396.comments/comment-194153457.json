{
	"id": 194153457,
	"body": "@rsc - thanks a lot for looking into it!\r\n\r\nRegarding what to look at - if you are running Density test (and apparently you are from the logs above), there are lines like these in the test:\r\n\r\n    Feb  2 14:31:39.621: INFO: Top latency metric: {Resource:nodes Verb:LIST Latency:{Perc50:121.186ms Perc90:378.483ms Perc99:652.822ms}}\r\n    Feb  2 14:31:39.621: INFO: Top latency metric: {Resource:pods Verb:LIST Latency:{Perc50:80.953ms Perc90:155.79ms Perc99:548.367ms}}\r\n    Feb  2 14:31:39.621: INFO: Top latency metric: {Resource:componentstatuses Verb:LIST Latency:{Perc50:260.097ms Perc90:260.097ms Perc99:260.097ms}}\r\n    Feb  2 14:31:39.621: INFO: Top latency metric: {Resource:nodes Verb:PUT Latency:{Perc50:14.102ms Perc90:20.246ms Perc99:250.619ms}}\r\n    Feb  2 14:31:39.621: INFO: Top latency metric: {Resource:nodes Verb:GET Latency:{Perc50:793Âµs Perc90:3.118ms Perc99:173.743ms}}\r\n\r\n[You can grep the logs for \"Top latency metric\".]\r\n\r\nAnd one line like this:\r\n\r\n    Mar  8 22:25:20.509: INFO: perc50: 1.48257294s, perc90: 2.211355607s, perc99: 2.614765988s\r\n\r\nThose are basically lines that we mostly focusing on.\r\n\r\n\r\nRegarding your second question - this painful loop should appear only if the test actually fails (metrics I mentioned above exceeded some threshold that we set up). In that case, we are trying to gather more logs for future debugging. From your perspective you can ^C them, but if you do that __you need to cleanup the the cluster__ after it so that you don't have some rubbish during the next run.\r\nThe easiest way to do that is to simply to:\r\n./stop-kubemark.sh\r\n./start-kubemark.sh\r\n[You don't need to touch the external cluster at all]. This is probably also the fastest solution (if you work at head, there is a better way to do - so let me know if I should describe it).\r\n\r\n\r\nBTW, looking into your logs I see:\r\n\r\n    STEP: Collecting events from namespace \"e2e-tests-density-7oooq\".\r\n    Mar  8 15:23:19.034: INFO: POD                 NODE         PHASE    GRACE  CONDITIONS\r\n    Mar  8 15:23:19.034: INFO: redis-master-ugeq9  10.245.2.28  Running         [{Ready False 0001-01- 01 00:00:00 +0000 UTC 2016-03-07 15:58:58 -0500 EST  }]\r\n    Mar  8 15:23:19.034: INFO: redis-master-ik3ua               Pending         []\r\n    Mar  8 15:23:19.034: INFO: redis-master-p2zsc  10.245.0.29  Running  30s    [{Ready False 0001-01-01 00:00:00 +0000 UTC 2016-03-07 15:59:03 -0500 EST  }]\r\n    Mar  8 15:23:19.034: INFO: pfpod               10.245.2.10  Running         [{Ready False 0001-01-01 00:00:00 +0000 UTC 2016-03-07 15:59:04 -0500 EST  }]\r\n\r\nThis is really strange - because we don't start any redis containers in this tests. Did you start them manually?",
	"user": {
		"login": "wojtek-t",
		"id": 10743879,
		"type": "User",
		"site_admin": false
	},
	"created_at": "2016-03-09T07:34:21Z",
	"updated_at": "2016-03-09T07:34:21Z"
}
