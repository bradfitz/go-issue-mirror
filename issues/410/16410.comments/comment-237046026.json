{
	"id": 237046026,
	"body": "Proposal LGTM! Some comments:\r\n\r\n\u003e The advantage of the hprof format is that there already exist many tools for analyzing hprof dumps. It will be a good idea to consider this format more throughly before making a decision.\r\n\r\nI vote against using hprof as the main format because it doesn't support interior pointers well. Everything is based on [object ID](https://java.net/downloads/heap-snapshot/hprof-binary-format.html). A lot of the interesting analyses we might want to do will need to understand interior pointers ([example](https://github.com/tombergan/goheapdump/blob/master/heapcheck/main.go#L28)).\r\n\r\n\u003e @rhysh Will the ELF core file described in the proposal doc be the same (on ELF-based systems) as one generated by GOTRACEBACK=crash or gcore(1)?\r\n\u003e What information is currently missing from Linux core dumps of Go programs that would be necessary to reconstruct the heap?\r\n\r\nGood questions that the proposal should answer. I believe there are three things we want to extract from the core dump, besides the usual DWARF data: (1) Dynamic types of interface values, (2) location of goroutine stacks, and (3) Where the GC thinks the pointers are. In theory, all of these can be extracted from an ordinary core file with DWARF data, but to do that, you need to walk the internal runtime structures. This means the heapdump library will need to change each time the runtime structs change, which could be annoying. The alternative idea is to embed (1,2,3) in a custom section of the ELF file using a stable format. This means less work for the heapdump library, however, it also means the heapdump library won't be able to process ordinary core files as generated by gcore.\r\n\r\nI have a slight preference for supporting ordinary core files, but am curious what others think. Note that the x/debug library [already has code](https://github.com/golang/debug/blob/master/server/server.go#L892) to walk some of the runtime structures. There's probably an opportunity to share code with that library.\r\n\r\n\u003e @matloob I think it would be good to start with your API interface (and as much of the code that's applicable to cores as heaps) golang.org/x/tools/cmd/heapview/internal and build from there. What do you think?\r\n\r\nSGTM. As @randall77 points out, that API I prototyped could use some pruning and cleaning. Don't be afraid to take a hatchet to it. Feel free to CC me on any CLs or assign me bits of work as they come up.\r\n\r\n\u003e @randall77 We absolutely want to have the dump analyzer/viewer to be able to handle large heaps. At the same time, I think designing the analyzer to somehow process the dump with O(1) space is a hard research problem. I don't want us to tackle that in v1.\r\n\r\nAgree with that completely, except I might replace \"hard\" with \"fun and distracting\" :-) The offline email thread with @alandonovan was more about the API than the implementation (not painting ourselves into a corner where the API becomes impossible to implement for large heaps).",
	"user": {
		"login": "tombergan",
		"id": 13954200,
		"type": "User",
		"site_admin": false
	},
	"created_at": "2016-08-02T21:13:56Z",
	"updated_at": "2016-08-03T03:48:33Z"
}
