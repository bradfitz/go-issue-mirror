{
	"id": 234678020,
	"body": "I've run the program with go1.7rc3 with CL 24706 PS 1 cherry-picked on top. gctrace and gcpacertrace output are below, along with an execution trace zoomed out to show what all 36 Ps are doing. There are indeed 9 that run a gcBgMarkWorker goroutine.\r\n\r\nI think I'll be able to distill this into a public benchmark, though I don't yet know how the GC pacer works. Can you give me some direction on what sorts of stimuli cause the assist ratio to be high or low?\r\n\r\nThe GC's behavior from what I'd expect in a few ways. Can you clarify what behavior I should expect?\r\n\r\n1. Allocation during a GC cycle is several orders of magnitude more expensive than allocation between GC cycles. I'd expect the cost difference to be less than 10x.\r\n2. The delay between a goroutine being runnable and it getting CPU time (\"scheduling latency\"?) is several orders of magnitude higher when a GC is running—say 7ms to receive inbound network traffic vs \u003c50µs typically. I'd expect the latency difference to be less than 10x for applications that are not CPU bound when the GC isn't running.\r\n3. In the execution trace below, all Ps are busy helping the collector between 50% and 80% of the way through the trace (550–562ms)—either directly via gcBgMarkWorker, or via assist taxes. I'd expect the GC's CPU usage to be relatively consistent throughout the cycle, for it to immediately enlist the help it needs, or to not enlist the help at all (at least not to the extent it does).\r\n4. At the very end of the concurrent GC phase, between 564ms and 566ms in the trace, the goroutine queue drains. The goroutines are each scheduled for more time than they are when the GC isn't running (compare with 568–570ms), but they each run quickly enough that the run queue drains. I'd expect the whole concurrent GC cycle to look like this, at least because it looks like confusion (1) isn't in play there.\r\n\r\nI think that (1) is the root of my surprise.\r\n\r\nIs (4) what you mean by \"the pacer pulling back\"? Does the pacer divide the GC into two (or more) phases, during which it imposes different allocation taxes?\r\n\r\nLooking again at [runtime.gcAssistAlloc](https://github.com/golang/go/blob/go1.7rc3/src/runtime/mgcmark.go#L395-L399):\r\n\r\n```\r\n\t// Compute the amount of scan work we need to do to make the\r\n\t// balance positive. We over-assist to build up credit for\r\n\t// future allocations and amortize the cost of assisting.\r\n\tdebtBytes := -gp.gcAssistBytes + gcOverAssistBytes\r\n\tscanWork := int64(gcController.assistWorkPerByte * float64(debtBytes))\r\n```\r\n\r\nI wonder if scanWork should be calculated differently. It looks like the goals the current code meets are:\r\n- get out of debt locally\r\n- stay on pace to get out of debt globally\r\n- don't get back into debt for a little while longer to amortize the cost of assisting\r\n\r\nI think the problems I'm seeing in my program are because:\r\n- the credit build-up for amortizing the cost of assisting is too high\r\n- the credit build-up is affected by the assist ratio, so becomes even higher (and is paid by a small number of goroutines)\r\n\r\nI'd propose something like the following, possibly with reducing the value of gcOverAssistBytes.\r\n\r\n```\r\n\tdebtBytes := -gp.gcAssistBytes\r\n\tscanWork := int64(gcController.assistWorkPerByte * float64(debtBytes))\r\n\tif scanWork \u003c gcOverAssistBytes {\r\n\t\tscanWork = gcOverAssistBytes\r\n\t\tdebtBytes = int64(gcController.assistBytesPerWork*float64(scanWork))\r\n\t}\r\n```\r\n\r\nWould a change like that break other invariants or goals of the GC?\r\n\r\n---\r\n\r\n```\r\npacer: assist ratio=+1.231154e+001 (scan 143 MB in 455-\u003e467 MB) workers=9+0\r\npacer: H_m_prev=245126496 h_t=+9.500000e-001 H_T=477996667 h_a=+9.557673e-001 H_a=479410384 h_g=+1.000000e+000 H_g=490252992 u_a=+8.475515e-001 u_g=+2.500000e-001 W_a=82463928 goalΔ=+5.000000e-002 actualΔ=+5.767295e-003 u_a/u_g=+3.390206e+000\r\ngc 899 @482.825s 4%: 0.14+26+1.2 ms clock, 4.7+572/227/0+41 ms cpu, 455-\u003e457-\u003e236 MB, 467 MB goal, 36 P\r\npacer: sweep done at heap size 254MB; allocated 18MB of spans; swept 60049 pages at +2.562095e-004 pages/byte\r\npacer: assist ratio=+1.252757e+001 (scan 147 MB in 460-\u003e472 MB) workers=9+0\r\npacer: H_m_prev=247813872 h_t=+9.500000e-001 H_T=483237050 h_a=+9.561490e-001 H_a=484760864 h_g=+1.000000e+000 H_g=495627744 u_a=+7.601246e-001 u_g=+2.500000e-001 W_a=83029592 goalΔ=+5.000000e-002 actualΔ=+6.149025e-003 u_a/u_g=+3.040498e+000\r\ngc 900 @483.353s 4%: 0.31+28+1.4 ms clock, 10+530/243/77+44 ms cpu, 460-\u003e462-\u003e230 MB, 472 MB goal, 36 P\r\npacer: sweep done at heap size 255MB; allocated 24MB of spans; swept 60107 pages at +2.626074e-004 pages/byte\r\npacer: assist ratio=+1.273292e+001 (scan 146 MB in 450-\u003e461 MB) workers=9+0\r\npacer: H_m_prev=242035808 h_t=+9.500000e-001 H_T=471969825 h_a=+9.541013e-001 H_a=472962480 h_g=+1.000000e+000 H_g=484071616 u_a=+8.154352e-001 u_g=+2.500000e-001 W_a=81893424 goalΔ=+5.000000e-002 actualΔ=+4.101271e-003 u_a/u_g=+3.261741e+000\r\ngc 901 @483.877s 4%: 0.093+25+1.2 ms clock, 2.9+532/225/1.0+38 ms cpu, 450-\u003e451-\u003e236 MB, 461 MB goal, 36 P\r\npacer: sweep done at heap size 265MB; allocated 29MB of spans; swept 58896 pages at +2.516126e-004 pages/byte\r\npacer: assist ratio=+1.214765e+001 (scan 143 MB in 460-\u003e472 MB) workers=9+0\r\npacer: H_m_prev=247497552 h_t=+9.500000e-001 H_T=482620226 h_a=+9.558650e-001 H_a=484071792 h_g=+1.000000e+000 H_g=494995104 u_a=+8.234678e-001 u_g=+2.500000e-001 W_a=81130152 goalΔ=+5.000000e-002 actualΔ=+5.864970e-003 u_a/u_g=+3.293871e+000\r\ngc 902 @484.398s 4%: 0.17+24+1.2 ms clock, 5.4+522/217/41+39 ms cpu, 460-\u003e461-\u003e238 MB, 472 MB goal, 36 P\r\npacer: sweep done at heap size 265MB; allocated 27MB of spans; swept 60644 pages at +2.568556e-004 pages/byte\r\npacer: assist ratio=+1.269908e+001 (scan 144 MB in 464-\u003e476 MB) workers=9+0\r\npacer: H_m_prev=249631648 h_t=+9.500000e-001 H_T=486781713 h_a=+9.570594e-001 H_a=488543968 h_g=+1.000000e+000 H_g=499263296 u_a=+9.082547e-001 u_g=+2.500000e-001 W_a=81885624 goalΔ=+5.000000e-002 actualΔ=+7.059419e-003 u_a/u_g=+3.633019e+000\r\ngc 903 @484.949s 4%: 0.43+23+1.3 ms clock, 2.5+566/204/0+8.0 ms cpu, 464-\u003e465-\u003e234 MB, 476 MB goal, 36 P\r\npacer: sweep done at heap size 259MB; allocated 25MB of spans; swept 61043 pages at +2.629836e-004 pages/byte\r\npacer: assist ratio=+1.248932e+001 (scan 145 MB in 456-\u003e468 MB) workers=9+0\r\npacer: H_m_prev=245437576 h_t=+9.500000e-001 H_T=478603273 h_a=+9.551745e-001 H_a=479873296 h_g=+1.000000e+000 H_g=490875152 u_a=+7.491987e-001 u_g=+2.500000e-001 W_a=81006200 goalΔ=+5.000000e-002 actualΔ=+5.174525e-003 u_a/u_g=+2.996795e+000\r\ngc 904 @485.456s 4%: 0.15+26+1.3 ms clock, 4.9+478/223/17+41 ms cpu, 456-\u003e457-\u003e238 MB, 468 MB goal, 36 P\r\npacer: sweep done at heap size 263MB; allocated 24MB of spans; swept 59909 pages at +2.528582e-004 pages/byte\r\npacer: assist ratio=+1.322047e+001 (scan 144 MB in 466-\u003e477 MB) workers=9+0\r\npacer: H_m_prev=250500912 h_t=+9.500000e-001 H_T=488476778 h_a=+9.621801e-001 H_a=491527904 h_g=+1.000000e+000 H_g=501001824 u_a=+8.063436e-001 u_g=+2.500000e-001 W_a=82953048 goalΔ=+5.000000e-002 actualΔ=+1.218010e-002 u_a/u_g=+3.225375e+000\r\ngc 905 @486.013s 4%: 0.77+28+1.4 ms clock, 24+581/245/0+46 ms cpu, 466-\u003e468-\u003e235 MB, 477 MB goal, 36 P\r\npacer: sweep done at heap size 253MB; allocated 17MB of spans; swept 61285 pages at +2.621329e-004 pages/byte\r\npacer: assist ratio=+1.300706e+001 (scan 149 MB in 460-\u003e471 MB) workers=9+0\r\npacer: H_m_prev=247202336 h_t=+9.500000e-001 H_T=482044555 h_a=+9.558154e-001 H_a=483482128 h_g=+1.000000e+000 H_g=494404672 u_a=+7.913021e-001 u_g=+2.500000e-001 W_a=84369712 goalΔ=+5.000000e-002 actualΔ=+5.815369e-003 u_a/u_g=+3.165208e+000\r\ngc 906 @486.606s 4%: 0.22+25+1.3 ms clock, 7.2+510/225/16+43 ms cpu, 460-\u003e461-\u003e236 MB, 471 MB goal, 36 P\r\npacer: sweep done at heap size 263MB; allocated 26MB of spans; swept 59549 pages at +2.537141e-004 pages/byte\r\n```\r\n\r\n![screen shot 2016-07-22 at 2 56 52 pm redacted](https://cloud.githubusercontent.com/assets/230685/17073199/68a5a988-5023-11e6-82cc-5b87ae9ec0d8.png)\r\n",
	"user": {
		"login": "rhysh",
		"id": 230685,
		"type": "User",
		"site_admin": false
	},
	"created_at": "2016-07-22T23:06:46Z",
	"updated_at": "2016-07-22T23:06:46Z"
}
