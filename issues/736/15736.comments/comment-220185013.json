{
	"id": 220185013,
	"body": "On Wed, May 18, 2016 at 3:51 PM, Josh Bleecher Snyder \u003c\nnotifications@github.com\u003e wrote:\n\n\u003e parallelizing packages and parallelizing compilation within a\n\u003e package (which we're also thinking about doing), are going after the same\n\u003e idle cycles\n\u003e\n\u003e Indeed. However, (a) there will always be inefficiencies in getting work\n\u003e scheduled, so doing both could help nevertheless and (b) as @bradfitz\n\u003e \u003chttps://github.com/bradfitz\u003e observed, scheduling compilation processes\n\u003e better helps a lot more if you start to ship compilation off over the\n\u003e network to other machines.\n\u003e\n\u003e Parallelizing compiles sounds like the code is easier, but it may make the\n\u003e system harder to manage - how many parallel compiles should be running?\n\u003e How much memory would that take? What if there's an error? The\n\u003e multiprocess spiderweb gets unwieldy after a while.\n\u003e\n\u003e cmd/go already parallelizes compiles, just not super efficiently; it\n\u003e already handles errors and juggles the spiderweb. That said, I rather\n\u003e dislike the cmd/go codebase, in part for this reason. :)\n\u003e\n\u003e cmd/go chooses ncpus as the number of parallel compiles to run, which can\n\u003e be altered with -p. My experiments with the -p flag so far indicate that\n\u003e doing fewer parallel compiles is clearly bad for wall time. And that\n\u003e despite the fact that cmd/compile actually already does rely on more than a\n\u003e single CPU (due to GC?): compiling with GOMAXPROCS=1 on my machine causes a\n\u003e roughly 30-50% slowdown.\n\u003e\n\u003e Also worth noting is that not all of cmd/go's work is in the compiler--cgo\n\u003e and resulting c compilations can be a big part of compile times, and those\n\u003e are not likely to be as core-saturating as cmd/compile anytime soon.\n\u003e\nTrue.\n\n\u003e So I'm inclined to say it is still worth pursuing both paths. And we have\n\u003e the tools to control concurrency on both fronts (-p, GOMAXPROCS), so\n\u003e benchmarking and experimentation is easy.\n\u003e\nScheduling multiple parallel-capable processes is tricky.  Suppose we're in\nthe middle of a build and there's only one compile that can be started.  Do\nwe give it all the rest of the available cpus?  Maybe the answer is yes.\nBut then what if a previously-issued compile completes and now a bunch of\nnew compiles are ready to go?  We've already committed almost all the\nprocessors to that one compile, so there aren't many left for all the\n(possibly on the critical path) compiles that are now ready.  Maybe we\ncould steal some processors back from the compile we already started?\nPretty soon we've reimplemented the entire Go work-stealing scheduler in\ncmd/go.\n\nI'm not saying we shouldn't do this.  I'd really like to have the tracing\noutput, at least.  But getting the parallelization right isn't easy and\nsplitting up the decision point into two different binaries won't help any.\n\n\u003e â€”\n\u003e You are receiving this because you commented.\n\u003e Reply to this email directly or view it on GitHub\n\u003e \u003chttps://github.com/golang/go/issues/15736#issuecomment-220181188\u003e\n\u003e\n",
	"user": {
		"login": "randall77",
		"id": 6889504,
		"type": "User",
		"site_admin": false
	},
	"created_at": "2016-05-18T23:11:11Z",
	"updated_at": "2016-05-18T23:11:11Z"
}
