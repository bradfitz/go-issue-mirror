{
	"id": 243956966,
	"body": "\r\nI was afraid of that. I follow much of that, but not all of it. \r\n\r\nSo let me just try to explain from a machine code level what can happen. We'll have to map this up to the Go reality later. \r\n\r\nSuppose I have this machine code: \r\n\r\nst r1, X                    // r1=1\r\n...context switch....  // took a context switch here (in your world that's some function call that allows it)\r\nld r2, X                   // read X back. \r\n\r\nIn Power, the st r1, X doesn't propagate to memory immediately (and in fact propagates to other processors and memory at varying points in time). So, memory write for the st r1, X can hang out in a queue on the processor you started executing on and not be visible to anyone else for a very long time unless a barrier pushes it around.  If the \u003ccontext switch\u003e bit doesn't have a barrier (an HWSYNC in this case) in the path, when the S/W thread here wakes up on the other processor, that other processor may not have yet seen the st r1, X and could easily see a stale cached version of X. So the ld r2, X can see \"0\" (assume inital before write of X is 0). \r\n\r\nThat's bad. Coherence (or uniprocessor data dependencies -- depending on who you're talking to) just went out the window. Don't cross the streams kinda bad......  \r\n\r\nThe way we cope with this in POWER is for context switches to have an HWSYNC. That also doesn't technically push the store out by itself (I'm fibbing a bit here, but it's close enough for this discussion), but what it does do is order the st X,1 ahead of the stores to whatever job queue control data structure that the H/W thread we're destined for will read in order to realize it can dispatch the S/W thread. So by the time the S/W thread dispatches on the new H/W thread,  the HWSYNC has ensured that the ST X,1 is visible to the new H/W thread. \r\n\r\nNormal programmers never see this. It just happens in the OS and no one is the wiser. Once you start taking on thread migration at a user level, however, you start feeling and having to manage these effects. \r\n\r\nSo when Ian said earlier something to the effect that \"everything else is in memory somewhere\", it's probably a bit more accurate to say that everything is at least on its way to memory and will get there eventually or when a barrier pushes it through.\r\n\r\nIt's really hard for me to imagine how you avoid this. Sadly it'll take me a long time to learn enough Go to read your scheduler code and look at the barriers in that and determine if that synchronization will fix this (unless there's an obvious HWSYNC that's executed on the departing thread :-)).\r\n\r\nAs an aside, I don't work for ARM, and I don't play an ARM engineer on television, but their memory model has a great many technical similarities to ours. As a matter of architecture, I would expect them to have similar issues. As a matter of most of the current implementations I've aware of, they may get away with skipping the barrier..... for now. You should check with them at some point. \r\n\r\nLet's agree about SYNC before we start into STCX/reservations. The case there is open for more debate.\r\n\r\nDerek\r\n\r\n",
	"user": {
		"login": "strikerdw",
		"id": 21373762,
		"type": "User",
		"site_admin": false
	},
	"created_at": "2016-09-01T02:14:05Z",
	"updated_at": "2016-09-01T02:14:05Z"
}
