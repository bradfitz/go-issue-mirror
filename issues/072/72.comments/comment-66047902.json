{
	"id": 66047902,
	"body": "\u003ca id=\"c7\"\u003e\u003c/a\u003eComment 7 by **jonas@pfenniger.name**:\n\n\u003cpre\u003eFor those trying to decide how much bits to allocate for time: time is relative to\nmany things and there is no such \"optimal\" representation. Your computer has many\nclocks with different guarantees, and more or less synchronized with an NTP server...\nor not. Time in interval and since an EPOCH are also very different. In the first\ncase you probably need more precision while on the other, it's more often used for\nuser representation. Seconds or minutes are enough. Birth of Jesus is not given at\n0.1Âµs precision :-p\n\nTo give an example, a common mistake is to use gettimeofday() to calculate a time\ninterval. \"gtod = gettimeofday(); while(gettimeofday() \u0026lt; gtod + 10000) { sleep(1); }\"\ncan hang for a long time if the user changes the system clock backwards since this\nclock source doesn't provide a monotonicity guarantee.\n\ntime.Sleep() should accept a time interval with high precision (millis or so) and use\na monotonic clock if possible to calculate that interval.\n\ncalendar, a new package that does calendar calculations on a DateTime interface for\nuser representation, so that application-specific time can also be handled by it.\n\nos.Time() returning a DateTime, with possibly a precision attribute.\n\nThis is the start of a proposal but I think it's better than having a unique\nrepresentation.\u003c/pre\u003e",
	"user": {
		"login": "gopherbot",
		"id": 8566911,
		"type": "User",
		"site_admin": false
	},
	"created_at": "2009-11-14T21:55:07Z",
	"updated_at": "2014-12-22T05:44:05Z"
}
