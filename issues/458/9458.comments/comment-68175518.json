{
	"id": 68175518,
	"body": "By \"append chaining\" I mean the behavior of a program after using append two or more times on a single slice header's \"descendants\", such that at least two of those results end up in different variables. At that point, the result is completely dependent on the given compiler's slice growth rules and it's effectively impossible to know the result via static analysis. (Not that I'm doing static analysis, but the point stands). In other words:\r\n\r\n    a = append(a, y)\r\n    b = append(a, x)\r\n    // do stuff with a and b\r\n\r\nAs for \"assuming append makes another slice\" -- I don't think it's a common explicit assumption. I do think, however, it's reasonable to assume code in the wild makes implicit assumptions about this because treating it that way fixed a bug or just happened to work correctly. I've certainly seen code on golang-nuts that tried (in vain) to use slices recursively and ran into some gnarly bugs like this so **someone** is doing weird stuff with slices.\r\n\r\nPerhaps it's true that only the tour/effective go/etc need to be updated. However, we'd have to agree to disagree that this is just the same sort of thing as a race or integer overflow. I think it's a bit more insidious and more likely to be a problem in a normal program, personally, but I'll grant it's subjective.\r\n\r\nIf I'm generous maybe I'd put it in the ballpark of floating point precision error and equality testing.",
	"user": {
		"login": "Jragonmiris",
		"id": 3078382,
		"type": "User",
		"site_admin": false
	},
	"created_at": "2014-12-27T11:06:48Z",
	"updated_at": "2014-12-27T11:15:35Z"
}
