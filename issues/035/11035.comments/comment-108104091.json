{
	"id": 108104091,
	"body": "    $ go version\r\n    go version devel +70cf735 Tue Jun 2 13:55:40 2015 +0000 linux/amd64\r\n\r\n\r\n@bradfitz / @ianlancetaylor Something funky is definitely going on. The\r\npointer that was marked at `0xdead` comes from a channel. Basically the\r\ncode looks like this:\r\n\r\n```go\r\ntype labelGraph struct {\r\n\tlabel []byte\r\n\tsg    *goiso.SubGraph\r\n}\r\n\r\ntype Collector struct {\r\n\tch   chan *labelGraph\r\n\ttree store.SubGraphs\r\n}\r\n\r\nfunc (c *Collector) send(sg *SubGraph) {\r\n\tlabel := sg.Label()\r\n\tc.ch\u003c-\u0026labelGraph{label, sg}\r\n}\r\n\r\nfunc (c *Collector) collect() {\r\n\tfor lg := range c.ch {\r\n\t\ttree.Add(lg.label, lg.sg)\r\n\t}\r\n}\r\n\r\nfunc (c *Collector) close() {\r\n\tclose(c.ch)\r\n}\r\n\r\nfunc otherThread() {\r\n\tgo c.collect()\r\n\tfor sg := range candidates {\r\n\t\tc.send(sg)\r\n\t}\r\n\tc.close()\r\n}\r\n```\r\n\r\nThe error was coming from deep inside the implementation of\r\n`tree.Add()`.\r\n\r\nIn `send(sg)` I added a check to make sure the values I was putting in\r\nwere sane. They always were. I added the same check inside of `Add()`.\r\nThere the check would fail. I pushed the check up one level to be inside\r\nof collect. It also failed there.\r\n\r\nSo basically, I was putting good values into the channel but getting\r\ndead values out. Super weird. If I turn off using the mmap'ed B+Tree and\r\nuse a regular datastructure the errors go away.\r\n\r\nI tried doing something which should have had no effect, I added\r\nbuffering to the channels.\r\n\r\n```go\r\n\tch: make(chan *labelGraph, 1)\r\n```\r\n\r\nThis made the error stop. Which is great.  However, now I get a new even\r\nmore mysterious error:\r\n\r\n    unexpected fault address 0xc208246c90\r\n    fatal error: fault\r\n    [signal 0xb code=0x2 addr=0xc208246c90 pc=0xc208246c90]\r\n\r\n    goroutine 200 [running]:\r\n    runtime.throw(0x602db0, 0x5)\r\n            /home/hendersont/srcs/go/src/runtime/panic.go:527 +0x96 fp=0xc208ef3dd8 sp=0xc208ef3dc0\r\n    runtime.sigpanic()\r\n            /home/hendersont/srcs/go/src/runtime/sigpanic_unix.go:27 +0x2ae fp=0xc208ef3e28 sp=0xc208ef3dd8\r\n    created by github.com/timtadh/fsm/mine.(*Miner).filterAndExtend\r\n            /home/hendersont/stuff/research/fsm/src/github.com/timtadh/fsm/mine/mine.go:235 +0x8e\r\n\r\nWhich looks like it might be a segmentation fault? These do not happen every\r\nrun. The other error was happening consistently. This error seems to only\r\nhappen when I use anonomous memory maps. If they are backed by files it does\r\nnot occur (well has not yet occurred).\r\n\r\nWhatever my program's problems are, the fragmentation problem in the runtime\r\nalso exists in 1.5. For instance after a successful run I get this with\r\n`GODEBUG=gctrace=1`\r\n\r\n    gc #13181 @266.838s 18%: 0+0+0+10+0 ms clock, 0+0+0+0/10/0+1 ms cpu, 4-\u003e4-\u003e3 MB, 4 MB goal, 4 P\r\n    gc #13182 @266.869s 18%: 0+0+12+8+0 ms clock, 0+0+0+4/8/0+1 ms cpu, 4-\u003e6-\u003e4 MB, 4 MB goal, 4 P\r\n    gc #13183 @266.885s 18%: 0+0+0+13+0 ms clock, 0+0+0+0/13/0+2 ms cpu, 4-\u003e4-\u003e3 MB, 7 MB goal, 4 P\r\n    gc #13184 @266.905s 18%: 0+0+0+11+0 ms clock, 0+0+0+0/11/0+1 ms cpu, 4-\u003e4-\u003e3 MB, 5 MB goal, 4 P\r\n    gc #13185 @266.929s 18%: 0+0+5+9+0 ms clock, 0+0+0+2/9/0+1 ms cpu, 4-\u003e5-\u003e3 MB, 5 MB goal, 4 P\r\n    gc #13186 @266.949s 18%: 0+0+0+7+5 ms clock, 0+0+0+0/7/0+23 ms cpu, 4-\u003e4-\u003e2 MB, 5 MB goal, 4 P\r\n    gc #13187 @266.988s 18%: 0+0+0+32+0 ms clock, 0+0+0+11/12/0+2 ms cpu, 4-\u003e7-\u003e4 MB, 4 MB goal, 4 P\r\n    gc #13188 @267.012s 18%: 0+0+3+14+0 ms clock, 0+0+0+0/14/0+2 ms cpu, 4-\u003e5-\u003e3 MB, 8 MB goal, 4 P\r\n    gc #13189 @267.033s 18%: 0+0+0+13+0 ms clock, 0+0+0+0/13/0+1 ms cpu, 4-\u003e5-\u003e3 MB, 5 MB goal, 4 P\r\n    gc #13190 @267.050s 18%: 0+0+0+10+0 ms clock, 0+0+0+0/10/0+2 ms cpu, 4-\u003e4-\u003e3 MB, 5 MB goal, 4 P\r\n    gc #13191 @267.082s 18%: 0+0+3+16+0 ms clock, 3+0+0+8/16/0+0 ms cpu, 4-\u003e5-\u003e3 MB, 5 MB goal, 4 P\r\n    gc #13192 @267.095s 18%: 0+0+0+7+0 ms clock, 0+0+0+0/7/0+2 ms cpu, 4-\u003e4-\u003e2 MB, 6 MB goal, 4 P\r\n    gc #13193 @267.127s 18%: 4+1+4+12+0 ms clock, 18+1+0+0/12/0+1 ms cpu, 4-\u003e6-\u003e3 MB, 5 MB goal, 4 P\r\n    gc #13194 @267.145s 18%: 0+0+0+10+0 ms clock, 0+0+0+0/10/0+0 ms cpu, 4-\u003e4-\u003e3 MB, 5 MB goal, 4 P\r\n    gc #13195 @267.170s 18%: 0+0+1+11+0 ms clock, 2+0+0+0/11/0+2 ms cpu, 4-\u003e5-\u003e3 MB, 5 MB goal, 4 P\r\n    gc #13196 @267.192s 18%: 0+0+1+10+0 ms clock, 0+0+0+0/10/0+2 ms cpu, 4-\u003e5-\u003e3 MB, 5 MB goal, 4 P\r\n    gc #13197 @267.215s 18%: 0+0+0+14+0 ms clock, 0+0+0+0/14/0+1 ms cpu, 4-\u003e4-\u003e3 MB, 5 MB goal, 4 P\r\n    gc #13198 @267.240s 18%: 0+0+3+10+0 ms clock, 3+0+0+0/10/0+2 ms cpu, 4-\u003e5-\u003e3 MB, 4 MB goal, 4 P\r\n    gc #13199 @267.260s 18%: 0+0+0+14+0 ms clock, 0+0+0+1/14/0+2 ms cpu, 4-\u003e4-\u003e3 MB, 4 MB goal, 4 P\r\n    gc #13200 @267.287s 18%: 0+0+6+9+0 ms clock, 0+0+0+0/9/0+1 ms cpu, 4-\u003e5-\u003e3 MB, 4 MB goal, 4 P\r\n    gc #13201 @267.318s 18%: 0+0+10+13+0 ms clock, 0+0+0+0/13/0+1 ms cpu, 4-\u003e5-\u003e4 MB, 5 MB goal, 4 P\r\n    gc #13202 @267.331s 18%: 0+0+0+9+0 ms clock, 0+0+0+0/9/0+2 ms cpu, 4-\u003e4-\u003e3 MB, 5 MB goal, 4 P\r\n    gc #13203 @267.367s 18%: 2+0+7+13+0 ms clock, 11+0+0+0/13/0+0 ms cpu, 4-\u003e5-\u003e3 MB, 5 MB goal, 4 P\r\n    gc #13204 @267.384s 18%: 0+0+0+9+0 ms clock, 0+0+0+0/9/0+1 ms cpu, 4-\u003e5-\u003e3 MB, 5 MB goal, 4 P\r\n    gc #13205 @267.416s 18%: 0+0+7+12+0 ms clock, 0+0+0+3/12/0+1 ms cpu, 4-\u003e6-\u003e3 MB, 5 MB goal, 4 P\r\n\r\n\r\nBut the resident size was continuing to grow at a healthy clip!\r\n\r\n![resource-usage](https://cloud.githubusercontent.com/assets/38620/7947587/0cbd18dc-094c-11e5-923e-03baaf5e7e8c.png)\r\n\r\nThis image shows the size of the memory mapped files (as files rather than\r\nanonmous mappings) versus the size of the heap which is growing (and continuing\r\nto grow actually out pacing the growth rate of the memory maps).\r\n\r\n### Conclusion\r\n\r\nIt looks like\r\n\r\n1. There might be a bug with respect to the unbuffered channels.\r\n   Difficult for me to tell if it is your bug or mine. Let me know if\r\n   you have any suggestions for sorting that out.\r\n\r\n2. The fragmentation is not fixed by the new collector. The target heap\r\n   size is fairly constantly around 4-8 MB but the heap grows at an\r\n   unbounded rate.\r\n\r\nI am interested in helping solve both problems. Let me know how I can\r\nhelp.\r\n\r\n",
	"user": {
		"login": "timtadh",
		"id": 38620,
		"type": "User",
		"site_admin": false
	},
	"created_at": "2015-06-02T21:31:33Z",
	"updated_at": "2015-06-02T21:31:33Z"
}
