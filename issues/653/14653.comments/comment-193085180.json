{
	"id": 193085180,
	"body": "Great job!\r\nHow many CPU cores were involved?\r\n\r\nUsing it in production code the problem is that often CPUs are a resource that may be used by concurrent tasks, so using more CPUs just to earn 15% may easily make the overall system slower due to less efficient use of the resources. That is the reason I think a robust base implementation that use a single thread must stay as default flavor inside `stdlib`.\r\n\r\nI'm trying to make a solution for a slightly different problem than `sort.Sort`:\r\n- **Big numbers**: we have more objects than usual to sort, so worth to use more CPUs in order to reduce the time to sort ideally by an order of magnitude.\r\n- **Being functional**: we want out of the box sort, we don't want to move the objects but instead to have a list of indices to be used later to iterate through the original series in a sorted fashion without touching the whole series. Suppose you need to iterate the same series in different manners and you don't want to make more copies of it.\r\n\r\nWhen we need to scale up, even `N log(N)` vs `N` can make the difference. The usage of more CPUs still should be either optional either close to the ideal scenario where speed is multiplied by number of cores.\r\n\r\nBut lets share the numbers I have on my machine in the last implementation [here](https://github.com/rressi/gobig):\r\n\r\n```sh\r\n$ GOMAXPROCS=1 go test -bench=. big\r\nPASS\r\nBenchmarkRadixSort_1k  \t    5000\t    368449 ns/op\r\nBenchmarkRadixSort_10k \t     500\t   3313324 ns/op\r\nBenchmarkRadixSort_100k\t      30\t  42800573 ns/op\r\nBenchmarkRadixSort_1M  \t       2\t 525938359 ns/op\r\nBenchmarkRadixSort_10M \t       1\t7420893394 ns/op\r\nBenchmarkSort_1k       \t    5000\t    248871 ns/op\r\nBenchmarkSort_10k      \t     500\t   3232176 ns/op\r\nBenchmarkSort_100k     \t      30\t  39452604 ns/op\r\nBenchmarkSort_1M       \t       2\t 574389730 ns/op\r\nBenchmarkSort_10M      \t       1\t7698980123 ns/op\r\nok  \tbig\t60.586s\r\n```\r\n\r\nWith only one CPU we have similar speeds, not good it is getting slightly better only for big numbers but not enough, function that generate the radix need improvements because we are still closer to `N log N` than to `N`.\r\n\r\nFor small numbers, no point, `sort.Sort` is better.\r\n\r\nLets scale up:\r\n\r\n```sh\r\n$ GOMAXPROCS=2 go test -bench=. big\r\nPASS\r\nBenchmarkRadixSort_1k-2  \t    5000\t    294862 ns/op\r\nBenchmarkRadixSort_10k-2 \t    1000\t   2186454 ns/op\r\nBenchmarkRadixSort_100k-2\t      50\t  25943125 ns/op\r\nBenchmarkRadixSort_1M-2  \t       5\t 306473763 ns/op\r\nBenchmarkRadixSort_10M-2 \t       1\t4313142617 ns/op\r\nBenchmarkSort_1k-2       \t    5000\t    247954 ns/op\r\nBenchmarkSort_10k-2      \t     500\t   3218643 ns/op\r\nBenchmarkSort_100k-2     \t      30\t  39316613 ns/op\r\nBenchmarkSort_1M-2       \t       2\t 578850846 ns/op\r\nBenchmarkSort_10M-2      \t       1\t7710922509 ns/op\r\nok  \tbig\t55.384s\r\n```\r\n\r\n| N | difference |\r\n|---|---|\r\n| 1k | -18% |\r\n| 10k | +32% |\r\n| 100k | + 34% |\r\n| 1M | +47% |\r\n| 10M | +44% |\r\n\r\nIt may worth the cost of using 2 CPUs, it may not.\r\n\r\nLets scale up:\r\n\r\n```\r\n$ GOMAXPROCS=4 go test -bench=. big\r\nPASS\r\nBenchmarkRadixSort_1k-4  \t    5000\t    251724 ns/op\r\nBenchmarkRadixSort_10k-4 \t    1000\t   1712307 ns/op\r\nBenchmarkRadixSort_100k-4\t      50\t  22316161 ns/op\r\nBenchmarkRadixSort_1M-4  \t       5\t 208881485 ns/op\r\nBenchmarkRadixSort_10M-4 \t       1\t2851469957 ns/op\r\nBenchmarkSort_1k-4       \t    5000\t    247612 ns/op\r\nBenchmarkSort_10k-4      \t     500\t   3225756 ns/op\r\nBenchmarkSort_100k-4     \t      30\t  39707499 ns/op\r\nBenchmarkSort_1M-4       \t       2\t 579981271 ns/op\r\nBenchmarkSort_10M-4      \t       1\t7748238902 ns/op\r\nok  \tbig\t48.582s\r\n```\r\n\r\n| N | difference |\r\n|---|---|\r\n| 1k | -2% |\r\n| 10k | +46% |\r\n| 100k | + 43% |\r\n| 1M | +63% |\r\n| 10M | +63% |\r\n\r\nIs clear that the CPU complexity of the 2 algorithms is still the same (my function extracting the radix is not efficient) but the new one is able to use more than one core but with not great efficiency.\r\n\r\nHere come the bad news, I added memory profiling to the game:\r\n\r\n```\r\n$ go test -bench=. -benchmem big\r\nPASS\r\nBenchmarkRadixSort_1k-4  \t    5000\t    254219 ns/op\t   59906 B/op\t     723 allocs/op\r\nBenchmarkRadixSort_10k-4 \t    1000\t   1702797 ns/op\t  422103 B/op\t    2685 allocs/op\r\nBenchmarkRadixSort_100k-4\t      50\t  22269063 ns/op\t 4228728 B/op\t   10617 allocs/op\r\nBenchmarkRadixSort_1M-4  \t       5\t 209942919 ns/op\t43352969 B/op\t   61476 allocs/op\r\nBenchmarkRadixSort_10M-4 \t       1\t2809521198 ns/op\t468514128 B/op\t  222642 allocs/op\r\nBenchmarkSort_1k-4       \t    5000\t    247852 ns/op\t      32 B/op\t       1 allocs/op\r\nBenchmarkSort_10k-4      \t     500\t   3219610 ns/op\t      32 B/op\t       1 allocs/op\r\nBenchmarkSort_100k-4     \t      30\t  39398951 ns/op\t      32 B/op\t       1 allocs/op\r\nBenchmarkSort_1M-4       \t       2\t 577199850 ns/op\t      32 B/op\t       1 allocs/op\r\nBenchmarkSort_10M-4      \t       1\t7674743659 ns/op\t      32 B/op\t       1 allocs/op\r\n```\r\n\r\n**Conclusion**: the new algorithm must be improved, before making a proposal.\r\n\r\n\r\n\r\n\r\n",
	"user": {
		"login": "rressi",
		"id": 11461454,
		"type": "User",
		"site_admin": false
	},
	"created_at": "2016-03-07T04:08:24Z",
	"updated_at": "2016-03-07T04:18:34Z"
}
