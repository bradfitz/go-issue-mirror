{
	"id": 66096118,
	"body": "\u003ca id=\"c7\"\u003e\u003c/a\u003eComment 7:\n\n\u003cpre\u003eA slice holding a single cached *machine costs something like 5 words (Lock + slice +\n1-element array) A pool holding a single cached *machine on a 4-CPU system costs\nsomething like 16*4 = 64 words. A factor of ten memory usage for a simple free list is\ntoo much. This is the kind of decision that makes microbenchmarks fast and overall\nprograms slow (because so much more memory is used).\n\nThe sync.Pool docs are very clear: it is for globals, singletons. It is not for things\nthat already have clearly defined lifetimes and can use the same lifetime for their\ncaches.\n\nPut another way, sync.Pool is for answering the question \"how do I decide when to drop\nthis cached thing that otherwise would never die\". The suggestion here is to use it to\nanswer the question \"how can I make this thing fast\". That's a mistake, even if the\nimplementation can satisfy both today. If it starts getting used for these two different\nthings, then we will not be able to change it, because optimizing for one case will hurt\nthe other.\n\nThe regexp free list is a Lock+slice. If that's so slow that it dominates real regexp\nexecution, then something is very wrong. What is it? Why are locks that slow? Are locks\nbroken? Is the scheduler broken? Is a locked free list just fundamentally incompatible\nwith multiprocessors? \n\nIf locks are broken, let's fix the locks.\nIf the scheduler is broken, let's fix the scheduler.\nIf a locked free list is fundamentally incompatible with multiprocessors - and you'll\nneed serious evidence to back this up - then maybe package sync needs to provide a\nfaster free list.\n\nNone of these answers involve using a sync.Pool in a context it is not intended for.\u003c/pre\u003e",
	"user": {
		"login": "rsc",
		"id": 104030,
		"type": "User",
		"site_admin": false
	},
	"created_at": "2014-06-19T03:15:49Z",
	"updated_at": "2014-12-08T10:45:41Z"
}
