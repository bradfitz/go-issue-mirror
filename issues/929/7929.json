{
	"id": 51287413,
	"number": 7929,
	"state": "open",
	"title": "x/net/html: Tokenizer cannot round-trip \u003cscript\u003e tag contents",
	"body": "by **martin@probst.io**:\n\n\u003cpre\u003eI'm not sure if this is a bug or working as intended according to the HTML5 parsing\nalgorithm, but it seems at least problematic from a user's perspective.\n\nWhen parsing an HTML document that contains \u0026lt;script\u0026gt; tags, writing out the tokens\nreceived will double escape any contained entities, thus \u0026lt;script\u0026gt; tags don't\nround-trip through the tokenizer. See the attached patch which adds two tests for\n\u0026lt;script\u0026gt;\u0026quot;\u0026lt;/script\u0026gt; (which leads to \u0026amp;#24; as the contents) and\n\u0026lt;script\u0026gt;\u0026amp;#34;\u0026lt;/script\u0026gt;, which leads to \u0026amp;amp;#34;.\n\nThat means re-parsing the output of tokenization adds more and more double escaping.\n\nThere is a test for \u0026lt;style\u0026gt; just below the one I added that makes this look\nintentional. But this is a real problem: using go.net/html to parse and re-serialize\ndocuments breaks the documents.\u003c/pre\u003e\n\n\n\n\n\nAttachments:\n\n1. \u003ca href=\"https://storage.googleapis.com/go-attachment/7929/0/script_tags_test.diff\"\u003escript_tags_test.diff\u003c/a\u003e (494 bytes)",
	"user": {
		"login": "gopherbot",
		"id": 8566911,
		"type": "User",
		"site_admin": false
	},
	"comments": 2,
	"created_at": "2014-05-03T12:20:48Z",
	"updated_at": "2015-04-14T19:16:59Z",
	"milestone": {
		"id": 1067491,
		"number": 22,
		"title": "Unreleased"
	}
}
