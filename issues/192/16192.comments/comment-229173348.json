{
	"id": 229173348,
	"body": "@randall77:\r\n\r\n\u003e The SSA backend encodes each addressing mode in a separate opcode. So for integer loads, we already already have:\r\n\u003e MOVBload, MOVBQSXload, MOVWload, MOVWQSXload, MOVLload, MOVLQSXload, MOVQload, MOVOload, MOVBloadidx1, MOVWloadidx1, MOVWloadidx2, MOVLloadidx1, MOVLloadidx4, MOVQloadidx1, MOVQloadidx8.\r\n\u003e Similarly for stores. And that's not all the loads, for instance we haven't implemented MOVWloadix4 yet.\r\n\u003e That's just the MOV opcode. Multiply that by ADD,SUB,AND,OR,XOR,MUL,DIV,NOT,NEG, and probably others. It gets pretty unwieldy pretty quickly.\r\n\u003e \r\n\u003e I'd like to solve this problem at some point. Maybe we bite the bullet and just do all those opcodes (and corresponding rewrite rules). Maybe we autogenerate somehow. It's low priority at the moment because I don't think it buys a whole lot (it's the same microops, just encoded more efficiently) and it's only x86. It's not needed for all the other architectures, and those are higher priority at the moment.\r\n\r\nYou are right that in the general case, using the read/modify/write opcodes doesn't make much difference to timing as generally the latency of the first move will be masked by the computations of the modify value so the difference is likely only ten to fifteen percent for a tight loop as here.  However, if one is optimizing using loop unrolling techniques (where the modify value is either immediate or a pre-calculated register), it can make a very large difference as in currently using a load followed by the very short modify followed by the store takes 3 clock cycles where it would take only 1 clock cycle for the read/modify/write instruction (both with no latency/dependency on the memory contents of the store/write).\r\n\r\nOften, for maximum speed, the base address will be a \"unsafe.Pointer\", which has the same read/load followed by modify followed by write/store template as currently used here (in fact it has another issue as it produces the simple base address for the MOV's by a LEA instruction when not necessary, which makes the timing even worse; I'll raise an Issue about that once I document it properly).\r\n\r\n\u003e \u003e Regarding addressing complexity, all the addressing modes are already used by the LEA instruction, although the execution time assessments don't seem quite right yet; it you solve that one, then the read/modify/write is solved except for latency.\r\n\r\n As I said, it seems you are already handling all of the addressing modes for LEA, although not the load/store variations; couldn't you just apply those rules to all the variations of the other opcodes?\r\n\r\nAnd autogeneration of the code seems to be the way to do it, as it would seem that the rules would be the same for each different load or store for each of the different opcodes.\r\n\r\nI can't comment on your priorities, and the current implementation of read then modify then write is \"adequate\", but we'll never compete with Cee \"extreme\" optimizations without this.",
	"user": {
		"login": "GordonBGood",
		"id": 10696269,
		"type": "User",
		"site_admin": false
	},
	"created_at": "2016-06-28T20:30:48Z",
	"updated_at": "2016-06-28T20:30:48Z"
}
