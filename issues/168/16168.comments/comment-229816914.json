{
	"id": 229816914,
	"body": "Possibly relevant for the following reason: I have a prototype running where the scheduler respects priorities. However, there's a race. Suppose we have a priority tree A -\u003e B -\u003e C. A should be served first. But A's frames won't be scheduled until A makes a Write call. The handlers all run concurrently, so it's possible that B or C will happen to make a Write call first, in which case their frames get written first because there's nothing (yet) queued for A. The scheduler doesn't know if it should wait for A (how long might it have to wait?), so it eagerly writes what it has. I have cases where this is a significant performance degradation relative to optimal delivery (10% worse).\r\n\r\nOne way to make the race less likely is to buffer multiple frames per stream. You still get the race on the first Write call, but at least after that call, A has a chance to generate more frames while its first frame is being written. (I haven't actually evaluated this idea.)\r\n\r\nSimon Pelchat and I are also kicking around the following idea: suppose we knew the connection's bandwidth. (We can estimate this from RTT and CWND from the kernel's tcp_info.) We could use this to pace the scheduler -- if the frame size is X, then we write one frame every X/bw seconds. As long as A can make Write calls faster than X/bw, it should always win the race. If it can't, we don't want to wait because we'd be leaving bandwidth on the floor. (Lots of potential problems with this idea, obviously.)",
	"user": {
		"login": "tombergan",
		"id": 13954200,
		"type": "User",
		"site_admin": false
	},
	"created_at": "2016-06-30T23:28:30Z",
	"updated_at": "2016-06-30T23:31:04Z"
}
