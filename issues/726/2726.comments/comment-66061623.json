{
	"id": 66061623,
	"body": "\u003ca id=\"c12\"\u003e\u003c/a\u003eComment 12:\n\n\u003cpre\u003eI see some room for improvement at cost of some memory. Now, the matching algorithm uses\n32k int array to store hashes and hash collisions prevent finding a match. Stupid\nincreasing the hashHead size (and changing several related constants accordingly), gives\nthe following result:\n\n-6: 1463307 (vs 1472391 above)\n-9: 1459164 (vs 1467823 above)\n\nThis is not immediately applicable because for some reason it slows down the encoder.\nAnyway, it's not a big deal to fix. Moreover, there is a good chance that using more\nmemory would speed up the encoder, because hash function would be simplified.\n\nAnother room for improvement is to allow to decrease the length of previous match by 1,\nif its length \u003e 3. It may have sense in case of the following text:\n\nzbcazzzzzzzzzzbc\n\nnow, if I am correct, the algorithm would take something like:\n\n[z][b][c][a][z][z][z](zzz)(zzzz)[b][c] // 11 tokens\n\nit may be improved as\n\n[z][b][c][a][z][z][z](zzz)(zzz)(zbc) // 10 tokens\n\nI will probably do something about this, once \u003ca href=\"http://golang.org/cl/5554066\"\u003ehttp://golang.org/cl/5554066\u003c/a\u003e is\nready and committed.\u003c/pre\u003e",
	"user": {
		"login": "krasin",
		"id": 21159,
		"type": "User",
		"site_admin": false
	},
	"created_at": "2012-01-20T07:14:43Z",
	"updated_at": "2014-12-08T10:14:30Z"
}
