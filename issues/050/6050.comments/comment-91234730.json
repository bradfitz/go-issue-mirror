{
	"id": 91234730,
	"body": "@keks Basically both. The scanner that's currently in the encoding/json package needs work. State is spread throughout the scanner and the decoder, and in places, the decoder actually does some of it's own scanning. In some places, scanning is done multiple times using different scanner instances, etc...\r\n\r\nI ended up having to rewrite portions of the scanner, so that's why it's taking me a while to make sure everything is well tested and structured. I wrote an underlying scanner that's simpler, then layered the Decoder on top of that, and added a higher-level api similar to what @aclements proposed. In addition, I have a \"walker\" helper class, that allows you to scan ahead to a particular node (using the underlying tokenizer) and then Decode or read tokens as needed. All of this is done using a forward only streaming model, so it should be very memory efficient regardless of the size of the document.\r\n\r\nI have not pushed the code to Gerrit yet. I don't know what the policy is on getting unfinished code out for review, but I wanted to make sure it was pretty well complete.  \r\n\r\nI am working to push it before the end of the week.",
	"user": {
		"login": "peterwald",
		"id": 5578,
		"type": "User",
		"site_admin": false
	},
	"created_at": "2015-04-09T13:39:27Z",
	"updated_at": "2015-04-09T13:39:27Z"
}
