{
	"id": 113640494,
	"number": 13067,
	"state": "open",
	"title": "database/sql: missing row fetch size and other optimizations for large dataset",
	"body": "I have been trying to work with large datasets in Oracle and mySQL DBs. There are around 20 million records in these databases. Idea was to use golang to pull and export them as JSON. While I was able to  use golang concurrency for export, I realized performance for pull from DB was VERY bad. Here is an estimate how bad it is:\r\ngolang (default driver setting): 30 min for 10 million (running next/scan in loop)\r\nI was able to find configuration options for one of the Oracle drivers (gopkg.in/rana/ora.v3) and after setting **PrefetchRowCount** to 50K, I was able to reduce time taken to 5 min.\r\n\r\nBig question, **why is there no standard way to provide hint to underlying driver in database/sql package about configuration parameters**(Or am I missing something here)? I think this is a big implementation issue, and will restrict golang use to very premetive scenarios around  databases. This will also encourage non stadard usage of drivers. PrefetchRowCount is just one example, and there are many others including language (NLS settings) etc. Both ODBC and JDBC specifications have very well articulated and provide lot of options for performance tuning, and other aspects around data retrieval. Having atleast some of those will certainly make life easier.\r\n",
	"user": {
		"login": "asambeka",
		"id": 11968926,
		"type": "User",
		"site_admin": false
	},
	"comments": 4,
	"created_at": "2015-10-27T17:40:14Z",
	"updated_at": "2016-09-28T16:14:00Z",
	"milestone": {
		"id": 1055141,
		"number": 6,
		"title": "Unplanned"
	}
}
